{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction Introduction Java Java中的注解是怎样工作的 Interceptor和Fliter的区别 Swagger Java知识总结 前端 Html5新特性 nodejs安装 React中使用fetch实现文件上传下载 前后端分离思考与实践 跨域问题 Linux Debian系统配置使用心得 Linux修改文件权限 Linux软件安装目录 Ubuntu安装MySql butnu解决zip中文乱码问题 Ubuntu18.04安装jdk 编程工具 git stash详解 git使用简单总结 玩转Intellij IDEA Tomcat部署常用命令 转载 一个从阿里面试回来的程序员的感想 用十年来学编程 从Intel和ARM争霸战，看看做芯片有多难 Ajxa已死，fetch永生 "},"docs/Java/":{"url":"docs/Java/","title":"Java","keywords":"","body":"Summary Java中的注解是怎样工作的 Interceptor和Fliter的区别 Swagger Java知识总结 "},"docs/Java/how-java-annotations-works.html":{"url":"docs/Java/how-java-annotations-works.html","title":"Java中的注解是怎样工作的","keywords":"","body":"什么是注解 用一个词就可以描述注解，那就是元数据，即一种描述数据的数据。所以，可以说注解就是源代码的元数据。比如，下面这段代码： @Override public String toString() { return \"This is String Representation of current object.\"; } 上面的代码中，重写了toString()方法并使用了@Override注解。 事实上，@Override告诉编译器这个方法是一个重写方法(描述方法的元数据)，如果父类中不存在该方法，编译器便会报错，提示该方法没有重写父类中的方法。如果不小心拼写错误，例如将toString()写成了toStrring(){double r}，而且也没有使用@Override注解，那程序依然能编译运行，但运行结果会和期望的大不相同。 Annotation是一种应用于类、方法、参数、变量、构造器及包声明中的特殊修饰符。它是一种由JSR-175标准选择用来描述元数据的一种工具。使用注解有助于阅读程序。 为什么要引入注解 使用Annotation之前(甚至在使用之后)，XML被广泛的应用于描述元数据。不知何时开始一些应用开发人员和架构师发现XML的维护越来越糟糕了。他们希望使用一些和代码紧耦合的东西，而不是像XML那样和代码是松耦合的(在某些情况下甚至是完全分离的)代码描述。如果你在Google中搜索“XML vs. annotations”，会看到许多关于这个问题的辩论。最有趣的是XML配置其实就是为了分离代码和配置而引入的。上述两种观点可能会让你很疑惑，两者观点似乎构成了一种循环，但各有利弊。下面我们通过一个例子来理解这两者的区别。 假如你想为应用设置很多的常量或参数，这种情况下，XML是一个很好的选择，因为它不会同特定的代码相连。如果你想把某个方法声明为服务，那么使用Annotation会更好一些，因为这种情况下需要注解和方法紧密耦合起来，开发人员也必须认识到这点。 另一个很重要的因素是Annotation定义了一种标准的描述元数据的方式。在这之前，开发人员通常使用他们自己的方式定义元数据。例如，使用标记interfaces，注释，transient关键字等等。每个程序员按照自己的方式定义元数据，而不像Annotation这种标准的方式。 注解是如何工作的 当注解标注到某个类或者方法或者某个成员变量或者某个输入参数上的时候，一定有一个对应的机制来对注解标注的类、方法、成员变量和参数进行某些处理。 编写Annotation非常简单，注解本身也可以说是一个类。可以将Annotation的定义同接口的定义进行比较。看个例子，标准的注解@Override： package java.lang; import java.lang.annotation.*; @Target(ElementType.METHOD) @Retention(RetentionPolicy.SOURCE) public @interface Override { } 可以看见，@Override注解似乎什么都没做，那它是如何检查在父类中有一个同名的函数？@Override注解的定义仅仅是元数据，不包含业务逻辑，而实现业务逻辑的就是注解的用户。 对于@Override注解，它的用户就是JVM虚拟机，工作在字节码层面，在编译阶段进行检查，其处理机制主要是JVM内部处理。 再例如Spring中的 @Service 注解，Spring在启动IOC容器的时候会对每个类进行扫描，把所有标注@Component及其子注解如@Service的类进行Bean处理。 编写自定义的注解 JDK5.0版本在 java.lang.annotation提供了四种元注解，专门注解其他的注解： @Documented – 是否将注解信息添加在java文档中 @Retention – 定义该注解的生命周期 @Target –注解用于什么地方 @Inherited – 是否允许子类继承该注解 @Retention 注解定义该注解的生命周期，在什么阶段丢弃， RetentionPolicy.SOURCE – 在编译阶段丢弃。这些注解在编译结束之后就不再有任何意义，所以它们不会写入字节码。@Override, @SuppressWarnings都属于这类注解。 RetentionPolicy.CLASS – 在类加载的时候丢弃，在字节码文件的处理中有用。注解默认使用这种方式。 RetentionPolicy.RUNTIME – 始终不会丢弃，运行期也保留该注解，因此可以使用反射机制读取该注解的信息。自定义的注解通常使用这种方式。 @Target – 表示该注解用于什么地方。如果不明确指出，该注解可以放在任何地方。属性的注解是兼容的。 ElementType.TYPE:用于描述类、接口或enum声明 ElementType.FIELD:用于描述实例变量 ElementType.METHOD ElementType.PARAMETER ElementType.CONSTRUCTOR ElementType.LOCAL_VARIABLE ElementType.ANNOTATION_TYPE 另一个注释 ElementType.PACKAGE 用于记录java文件的package信息 那么，注解的内部到底是如何定义的呢？Annotations只支持基本类型、String及枚举类型。注释中所有的属性被定义成方法，并允许提供默认值。 定义一个 @AuthCheck 注解，作用在SpringMVC controller的方法上。 package com.liuning.sys.auth; import static java.lang.annotation.ElementType.METHOD; import java.lang.annotation.Documented; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Documented @Target(METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface AuthCheck { String value() default \"\"; } 注解中只有一个属性，可以直接命名为“value”，使用时无需再标明属性名。 在Spring的拦截器HandlerInterceptor中实现@AuthCheck注解的业务逻辑，这里使用了反射机制。 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { HandlerMethod hm = (HandlerMethod) handler; AuthCheck ac = hm.getMethodAnnotation(AuthCheck.class); if (ac != null) { if (ac.value() == \"Login\") { //进行业务逻辑操作 } } return true; } 下面的例子演示了如何使用上面的注解。使用了该注解的方法在用户调用的时候会需要用户已登录。 @PostMapping(\"/list\") @AuthCheck(value = \"Login\") public List getUserList(@RequestBody @Valid User user) { return userService.getUserList(user); } "},"docs/Java/difference-between-interceptor-and-filter.html":{"url":"docs/Java/difference-between-interceptor-and-filter.html","title":"Interceptor和Fliter的区别","keywords":"","body":" Interceptor 主要作用：拦截用户请求，进行处理，比如判断用户登录情况、权限验证，只要针对Controller请求进行处理，是通过HandlerInterceptor。 Interceptor分两种情况，一种是对会话的拦截，实现spring的HandlerInterceptor接口并注册到mvc的拦截队列中，其中preHandle()方法在调用Handler之前进行拦截(上图步骤3)，postHandle()方法在视图渲染之前调用(上图步骤5)，afterCompletion()方法在返回相应之前执行；另一种是对方法的拦截，需要使用@Aspect注解，在每次调用指定方法的前、后进行拦截。 Filter 主要作用：过滤字符编码、做一些业务逻辑判断，主要用于对用户请求进行预处理，同时也可进行逻辑判断。 Filter在请求进入servlet容器执行service()方法之前就会经过filter过滤（上图步骤1），不像Intreceptor一样依赖于springmvc框架，只需要依赖于servlet。Filter启动是随WEB应用的启动而启动，只需要初始化一次，以后都可以进行拦截。 Filter有如下几个种类： 用户授权Filter：检查用户请求，根据请求过滤用户非法请求； 日志Filter：记录某些特殊的用户请求； 解码Filter：对非标准编码的请求解码。 Filter和Interceptor的区别 Filter是基于函数回调（doFilter()方法）的，而Interceptor则是基于Java反射的（AOP思想）。 Filter依赖于Servlet容器，而Interceptor不依赖于Servlet容器。 Filter对几乎所有的请求起作用，而Interceptor只能对action请求起作用。 Interceptor可以访问Action的上下文，值栈里的对象，而Filter不能。 在action的生命周期里，Interceptor可以被多次调用，而Filter只能在容器初始化时调用一次。 Filter在过滤是只能对request和response进行操作，而interceptor可以对request、response、handler、modelAndView、exception进行操作。 "},"docs/Java/swagger.html":{"url":"docs/Java/swagger.html","title":"Swagger","keywords":"","body":"Swagger是一个流行的API开发框架，这个框架以“开放API声明”（OpenAPI Specification，OAS）为基础，对整个API的开发周期都提供了相应的解决方案，是一个非常庞大的项目（包括设计、编码和测试，几乎支持所有语言）。 OAS本身是一个API规范，它用于描述一整套API接口，包括一个接口是GET还是POST请求啊，有哪些参数哪些header啊，都会被包括在这个文件中。它在设计的时候通常是YAML格式，这种格式书写起来比较方便，而在网络中传输时又会以json形式居多，因为json的通用性比较强。 由于Spring的流行，Marty Pitt编写了一个基于Spring的组件swagger-springmvc，用于将swagger集成到springmvc中来。而springfox则是从这个组件发展而来，同时springfox也是一个新的项目，本文仍然是使用其中的一个组件springfox-swagger2。 pringfox-swagger2依然是依赖OSA规范文档，也就是一个描述API的json文件，而这个组件的功能就是帮助我们自动生成这个json文件，我们会用到的另外一个组件springfox-swagger-ui就是将这个json文件解析出来，用一种更友好的方式呈现出来。 在开始编码之前，我们先对配置的流程有个大致的了解。 在前言中，我们知道，我们的第一个任务就是生成一个满足OSA规范的json文件（当然，创建一个spring的项目就不说了）。对于这个任务，springfox为我们提供了一个Docket（摘要的意思）类，我们需要把它做成一个Bean注入到spring中，显然，我们需要一个配置文件，并通过一种方式（显然它会是一个注解）告诉程序，这是一个Swagger配置文件。 一个OSA规范文档需要许多信息来描述这个API，springfox允许我们将信息组合成一个ApiInfo的类，作为构造参数传给Docket（当然也可以不构造这个类，而直接使用null，但是你的这个API就太low了）。 接下来，我们要写控制器了，当然这不重要，不用springfox你依然要写控制器，重要的是要告诉springfox，这个控制器是一个需要他来收集API信息的控制器，不用说，这依然会采用注解的方式，同时，我们为了将配置文件与控制器结合起来，需要在配置文件中指明在什么位置收集可能是API的控制器的信息。 到这里，生成OSA规范的json文件的配置就结束了。虽然生成过程比我叙述的更复杂，但这些程序都会帮我们完成，我们可以通过类似http://localhost:8080/demo/v2/api-docs的路径来查看这个json文件。这个v2/api-docs就是springfox默认的生成文档的路径。 接下来，我们需要将它可视化显示出来，如果使用swagger-springmvc，我们需要单独去下载一个swagger ui的显示页面包，并将其中的路径改为上面的http://localhost:8080/demo/v2/api-docs，这里你就可以感受到，swagger ui就是在解析一个json文件了。你依然可以这么做，不过springfox专门提供了一个springfox-swagger-ui组件，不需要配置，我们只需要引入这个依赖的组件就可以看到最终的效果了，而这个路由会是http://localhost:8080/demo/swagger-ui.html。 Maven依赖配置 io.springfox springfox-swagger2 2.6.1 io.springfox springfox-swagger-ui 2.6.1 Configuration类配置 @Configuration @EnableSwagger2 @EnableWebMvc public class SwaggerConfig { @Bean public Docket customDocket() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage( \"com.liuning.springswagger.controller\")) .build(); } private ApiInfo apiInfo() { Contact contact = new Contact( \"LiuNing\", \"https://springfox.github.io/springfox/\", \"liuning@cqfmbank.com\" ); return new ApiInfoBuilder() .title(\"开放平台接口\") .description(\"open-api接口\") .contact(contact) .version(\"1.1.0\") .build(); } } 跑别人的demo，自己加上swagger，但是却访问不了，最后发现是因为默认的路径被 @EnableWebMvc覆盖掉 或者说是 继承WebMvcConfigurerAdapter类后，默认的静态资源路径对swagger-ui.html访问不起作用， 因此要重写 WebConfigurer（继承WebMvcConfigurerAdapter的那个类） 的一个方法。 @Configuration public class WebMvcConfig extends WebMvcConfigurerAdapter { @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\"/static/**\") .addResourceLocations(\"classpath:/static/\"); registry.addResourceHandler(\"swagger-ui.html\") .addResourceLocations(\"classpath:/META-INF/resources/\"); registry.addResourceHandler(\"/webjars/**\") .addResourceLocations(\"classpath:/META-INF/resources/webjars/\"); } } "},"docs/Java/summary-of-java.html":{"url":"docs/Java/summary-of-java.html","title":"Java知识总结","keywords":"","body":" JVM中虚拟栈中存的是对象的地址（引用），创建的对象实质在堆中。 java中的接口支持多继承，即一个子接口可以有多个父接口。 Jsp是java开发的专门用于动态显示页面的技术。jsp编译时首先编译成servlet文件，然后编译成class文件。 包含9大内置对象： response、request、exception、out、application、pagecontext、config、session、page。 有四个域对象： request、pagecontext、session、application 多态：父类的引用指向子类的实例。 Comparable & Comparator 都是用来实现集合中元素的比较、排序 只是 Comparable 是在集合内部定义的方法实现的排序，Comparator 、是在集合外部实现的排序， 所以，如想实现排序，就需要在集合外定义 Comparator 接口的方法或在集合内实现 Comparable 接口的方法。 Comparator位于包java.util下，而Comparable位于包 java.lang下 Comparable 是一个对象本身就已经支持 自比较所需要实现的接口（如 String、Integer 自己就可以完成比较大小操作，已经实现了Comparable接 口） 自定义的类要在加入list容器中后能够排序，可以实现Comparable接口， 在用Collections类的sort方法排序时，如果不指定Comparator，那么就以自然顺序排序， 这里的自然顺序就 是实现Comparable接口设定的排序方式。 而 Comparator 是一个专用的比较器，当这个对象不支持自比较或者自比较函数不能满足你的要求时，你可 以写一个比较器来完成两个对象之间大小的比较。 可以说一个是自已完成比较，一个是外部程序实现比较的差别而已。 用 Comparator 是策略模式（strategy design pattern），就是不改变对象自身，而用一个策略对象 （strategy object）来改变它的行为。 比如：你想对整数采用绝对值大小来排序，Integer 是不符合要求的， 你不需要去修改Integer 类（实际上你也不能这么做）去改变它的排序行为，只要使用一个实现了 Comparator 接口的对象来实现控制它的排序就行了。 Java中的length属性是针对数组 比如说你声明了一个数组,想知道这个数组的长度则用到了length这个属性. Java中的length()方法是针对字符串String说的,如果想看这个字符串的长度则用到length()这个方法. Java中的size()方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看! 7、super和this的异同 super（参数）：调用基类中的某一个构造函数（应该为构造函数中的第一条语句） this（参数）：调用本类中另一种形成的构造函数（应该为构造函数中的第一条语句） super:　它引用当前对象的直接父类中的成员（用来访问直接父类中被隐藏的父类中成员数据或函数，基类与派生类中有相同成员定义时如： super.变量名 super.成员函数据名（实参） this：它代表当前对象名（在程序中易产生二义性之处，应使用this来指明当前对象；如果函数的形参与类中的成员数据同名，这时需用this来 指明成员变量名） 调用super()必须写在子类构造方法的第一行，否则编译不通过。每个子类构造方法的第一条语句，都是隐含地调用super()，如果父类没有这 种形式的构造函数，那么在编译的时候就会报错。 super()和this()类似,区别是，super()从子类中调用父类的构造方法，this()在同一类内调用其它方法。 super()和this()均需放在构造方法内第一行。 尽管可以用this调用一个构造器，但却不能调用两个。 this和super不能同时出现在一个构造函数里面，因为this必然会调用其它的构造函数，其它的构造函数必然也会有super语句的存在，所以 在同一个构造函数里面有相同的语句，就失去了语句的意义，编译器也不会通过。 this()和super()都指的是对象，所以，均不可以在static环境中使用。包括：static变量,static方法，static语句块。 从本质上讲，this是一个指向本对象的指针, 然而super是一个Java关键字 1.由于构造器的名字必须与类名相同，而匿名类没有类名，所以匿名类不能有构造器。 8.匿名内部类的创建格式为： new 父类构造器（参数列表）|实现接口（）{ //匿名内部类的类体实现 } 使用匿名内部类时，必须继承一个类或实现一个接口 匿名内部类由于没有名字，因此不能定义构造函数 匿名内部类中不能含有静态成员变量和静态方法 （1）对于外部类而言，它也可以使用访问控制符修饰，但外部类只能有两种访问控制级别： public 和默认。 因为外部类没有处于任何类的内部，也就没有其所在类的内部、所在类的子类两个范围，因此 private 和 protected 访问控制符对外部类没有意义。 （2）内部类的上一级程序单元是外部类，它具有4个作用域：同一个类（private）、同一个包（protected） 和任何位置（ public ）。 （3）因为局部成员的作用域是所在方法，其他程序单元永远不可能访问另一个方法中的局部变量，所以所有的 局部成员都不能使用访问控制修饰符修饰 9.可以把局部内部类当做一个局部变量，所以它是不需要加任何修饰符的局部内部类前不能用修饰符public和private,protected 10.成员变量有初始值，而局部变量没有初始值得. "},"docs/Front/":{"url":"docs/Front/","title":"前端","keywords":"","body":"Summary Html5新特性 nodejs安装 React中使用fetch实现文件上传下载 前后端分离思考与实践 跨域问题 "},"docs/Front/html5-new-feature.html":{"url":"docs/Front/html5-new-feature.html","title":"Html5新特性","keywords":"","body":"HTML5新特性 语义化标签，如header、footer、nav、section、aside等 增强型表单，color、date、email、month、tel、time等新增的表单Input输入类型，placeholder、required、pattern、min、max、height、width等新增的表单属性 音频和视频文件播放的标准，用audio元素 Canvas绘图 地理位置，window.navigator.geolocation用于定位用户的位置 拖放API Web Storage，客户端存储数据的两个对象：localStorage sessionStorage WebSocket，html5提供的一种在单个TCP连接上进行全双工通讯的协议 DOM扩展 HTML5增加了的getElementByClassName()方法是最受人欢迎的一个方法，可以通过document对象及所有HTML元素调用该方法。 "},"docs/Front/install-nodejs.html":{"url":"docs/Front/install-nodejs.html","title":"nodejs安装","keywords":"","body":"官网下载源码包,解压安装,如果要安装不同版本则只需要改变版本号即可 wget https://nodejs.org/dist/v8.11.3/node-v8.11.3.tar.gz tar -zxvf node-v8.11.3.tar.gz cd node-v8.11.3 ./configure make && make install 可能出现报错 只需要安装 sudo yum -y install gcc automake autoconf libtool make sudo yum install gcc gcc-c++ 然后再执行make命令就可以了,时间可能会很长. 配置NODE_HOME，进入profile编辑环境变量 vim /etc/profile -export NODE_HOME=/usr/local/node/0.10.24 -export PATH=$NODE_HOME/bin:$PATH source /etc/profile 验证是否配置成功 node -v npm（node package manager）nodejs的包管理器，用于node插件管理（包括安装、卸载、管理依赖等） ,一般npm会在弄得安装时自动安装 由于npm的官网镜像下载很慢，所以建议先按个cnpm，连接淘宝提供的npm库 npm install -g cnpm 全局安装gulp cnpm install gulp -g gulp -v 查看已安装的npm包 npm list -g --depth 0 全局安装模块xxx npm install -g xxx 安装并写入package.json的\"dependencies\"中 npm install xxx --save 安装并写入package.json的\"devDependencies\"中 npm install xxx --save-dev 删除xxx模块 npm uninstall xxx 删除全局模块xxx npm uninstall -g xxx 查看npm配置 npm config list http://www.cnblogs.com/penghuwan/p/6973702.html npm cache clean --force //强制清除缓存 "},"docs/Front/react-upload-and-download-file.html":{"url":"docs/Front/react-upload-and-download-file.html","title":"React中使用fetch实现文件上传下载","keywords":"","body":"在最近的项目中需要实现文件上传下载功能，在以前spring、jsp的项目中实现文件上传很简单，但现在前后端分离，前端使用React，后端使用Spring Boot，实现就没那么方便了。 前端React使用fetch而非传统的XMLHttpRequest从后端获取Json数据，那么文件上传自然而然也要使用fetch了。 在react中使用fetch上传文件不难，代码如下： handleUpload = (e) => { e.preventDefault(); let file = e.target.files[0]; const formdata = new FormData(); formdata.append('file', file); for (var value of formdata.values()) { console.log(value); } const url = 'http://127.0.0.1:8080/file/upload'; fetch(url, { method: 'POST', body: formdata, headers: { \"Content-Type\": \"multipart/form-data\" } }).then(response => return response.json();) .catch(error => console.log(error)); }; 上述实现使用了原生的fetch方法，没有做任何的封装，同时还使用了FormData对象。 在实际操作中，遇到了一个坑，在跨域请求时不能自定义头部，需要去掉headers，否则POST请求会变成OPTIONS请求。 fetch实现文件下载就要相对麻烦一些。 下载原理很简单，就是模拟a标签的点击下载，ajax 不支持下载文件功能，是因为 ajax 只能用来传输字符型数据，所以在过去无法使用 ajax 来下载文件。 fetch可以把 response 保存为 blob，下载结束后，为这个 blob 创建一个 URL，跳转到这个URL，或使用 anchor element with download property ，浏览器会弹出保存框。如果文件很大的话，还需要用到 filesystem API，因为 blob 是存在内存中的。 const params = { group: group, path: path }; //可以根据需求传特定的一些参数 const downloadUrl = 'http://127.0.0.1:8080/file/download'; fetch(downloadUrl, { method: 'POST', body: window.JSON.stringify(params), credentials: 'include', headers: new Headers({ 'Content-Type': 'application/json' }) }).then((response) => { response.blob().then( blob => { let blobUrl = window.URL.createObjectURL(blob); //不能直接创建一个标签 // let a = document.createElement('a_id'); let a = document.getElementById('a_id'); //无法从返回的文件流中获取文件名 // let filename = response.headers.get('Content-Disposition'); let filename = 'file.txt'; a.href = blobUrl; a.download = filename; a.click(); window.URL.revokeObjectURL(blobUrl); }); }).catch((error) => { console.log(error); }); 这样就在React中使用fetch实现了文件上传下载，先这样，有问题后面再补充。 "},"docs/Front/divide-between-frontend-and-backend.html":{"url":"docs/Front/divide-between-frontend-and-backend.html","title":"前后端分离思考与实践","keywords":"","body":"传统技术 前后端的代码存放在同一个工程目录下，前后端工程师进行开发时，都必须把整个项目导入到开发工具中（像myEclipse和IntelliJ IDEA等） 一方面前端在开发之前需要花费大量的时间来部署开发环境，如果后端上传错了文件，整个系统启动不起来，前端就只能干等着，前后端耦合性很大， 另一方面使用myEclipse这样的开发工具开发前端项目操作上不熟悉，开发效率很低 什么是前后端分离 这几年前后端分离被提到的越来越多，在网上查什么是前后端分离，基本是说后台只提供数据api，与用户的交互操作前端来实现。 我们现在的工作模式，前端也是通过ajax请求后台数据，前端的代码单独放在工程目录的一个文件夹中，不与后台的代码耦合，这算不算前后端分离。 前后端分离是前后端代码库分离，前端代码中有可以进行Mock测试(通过构造虚拟测试对象以简化测试环境的方法)的伪后端，能支持前端的独立开发和测试。 而后端代码中除了功能实现外，还有着详细的测试用例，以保证API的可用性，降低集成风险。 跨域问题 1.react当中解决跨域问题用proxy可以实现 对于使用creat-react-app构建的项目，可以直接在package.json下配置，具体如下 1 \"proxy\": \"http://api.xxxx.com\" 如果同时使用多个域，配置如下 //package.json中加入 \"proxy\": { \"/api/RoomApi\": { \"target\": \"http://open.douyucdn.cn\", \"changeOrigin\":true }, \"/api/v1\":{ \"target\":\"http://capi.douyucdn.cn\", \"changeOrigin\":true } } 2.使用nodejs中的http-proxy-middleware插件 3.使用jsonp，但是不支持post请求方式 4.后台配置cors，但是ie67完全不兼容，ie89需要做一些特殊处理，ie10以上才能使用 后两种需要后台大拿配合 好了跨域的问题解决了，那么如果是react怎么请求后台数据？ 数据请求 ajax、axios、fetch jquery ajax是使用最多的一种方式，问题是jQuery文件太大，react中单纯的使用ajax就引入jquery不太合理 Axios 是一个基于promise的HTTP库，可以用在浏览器和node.js中。简单易用，功能强大。兼容性方面要低于jQuery的ajax，支持ie9以上。提供了很多并发请求的接口，方便了很多。 fetch更加底层，写法很方便，缺点是只对网络请求报错，对400，500都当作成功的请求，需要封装处理。 上线统一部署 前端代码开发完成后如何与后台代码统一部署呢，这里就用到了webpack之类的打包工具 使用打包工具可以把前端项目打包成静态压缩文件，即一个index.html一个css一个js压缩文件 然后把他们放在后台工程目录里面运行整个项目就行了，这里要注意文件路径问题，并且之前的跨域处理也要去掉。 对于使用creat-react-app构建的项目，可以使用npm run build来打包 到此，整个使用react的流程就基本搞清了，接下来就是实际的开发工作，react的使用，es6的语法都是重中之重 "},"docs/Front/cors.html":{"url":"docs/Front/cors.html","title":"跨域问题","keywords":"","body":"https://blog.csdn.net/cc1314_/article/details/78272329 https://blog.csdn.net/web0718h5/article/details/75907252?utm_source=blogxgwz2 "},"docs/Linux/":{"url":"docs/Linux/","title":"Linux","keywords":"","body":"Summary Debian系统配置使用心得 Linux修改文件权限 Linux软件安装目录 Ubuntu安装MySql butnu解决zip中文乱码问题 Ubuntu18.04安装jdk "},"docs/Linux/debian-system-config.html":{"url":"docs/Linux/debian-system-config.html","title":"Debian系统配置使用心得","keywords":"","body":"经过自己作死般不停地瞎折腾，抛弃了Ubuntu又给电脑装上了Debian。 这么些天折腾下来，什么技术没学到，Linux发行版倒是体验了好几种，我想Debian应该是最终的选择了吧，呵呵。 选择Debian的原因也很简单，Ubuntu更多是一个桌面发行版，做了很多桌面优化使得它的界面看上去很漂亮（重点是我觉得很丑），对系统的资源占用率相对较Debian要高些。我的电脑又是刚上大学时买的一台很垃圾的华硕笔记本，到现在用着已经很吃力了。 经过比较，安装后Ubuntu后内存占用1.4G左右，而安装Debian后内存占用1G左右，这小小的差距让我心里平衡了一些。Debian的界面看上去清爽了很多，Ubuntu看上去就跟个紫薯精一样，我是真的无法理解Ubuntu的界面漂亮在哪里。 使用Debian后就会发现Ubuntu是多么省事，要想日常用上Debian还得克服重重阻碍。 1.系统窗口最大化最小化 安装好Debian新系统后，第一件事就是打开系统自带的火狐浏览器，发现居然只有关闭按钮而没有最大化最小化按钮，这真的是让我很蛋疼了。 解决方法很简单，在终端输入 gnome-tweak-tool 打开设置窗口： 在桌面栏开启桌面图标 在窗口栏开启最大化和最小化按钮显示 因为没有开启桌面图标，打开终端都得在应用程序里面找，而且没有安装中文支持，所有的界面都是英文的。 2.添加终端快捷键 Debian默认是没有终端的快捷键的需要自己定义，设置的方法也很简单，打开设置->键盘，滑到底部用户自定义快捷键。 名称：Terminal 命令：gnome-terminal 快捷键：Ctrl + Alt + T 这样终端的快捷键就设置成功。 3.修改软件源设置 用apt-get安装软件包时提示让我插入netinst的光盘，莫名奇妙 Media change:please insert the disc labeled 这时需要打开/etc/apt/sources.list文件，注释掉cdrom那一行，再执行apt-get update更新下deb仓库，再使用apt-get安装时就不会搜寻cdrom了。 接着安装vim apt-get install vim E:Package 'vim-gtk' has no installation candidate 真的是坑爹，解决方法就是修改软件源设置 备份源文件 cp -i /etc/apt/sources.list /etc/apt/sources.list_backup 打开sources.list gedit /etc/apt/sources.list 在源文件中加入如下阿里巴巴的阿里云服务器的地址并保存 deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse 更新 apt-get update 这样问题就解决了，安装vim也不会再报错了。 4.安装sudo并添加sudoers 前面的这些操作都是在root用户下操作的，和Ubuntu不同，Debian在安装过程中会让你选择添加root用户和普通用户，这也是我推荐的一种做法。 但是普通用户需要执行一些root命令时总不能每次都su root切换到root用户吧？于是需要安装一下sudo apt-get install sudo sudo能够完成很多root用户能完成的工作，它们之间也有一定的区别，执行sudo时需要的是普通用户的密码。 安装完sudo执行命令后还是会报错 xxx is not in the sudoers file.This incident will be reported. 显然，需要在sudoers文件中添加当前用户 切换到root，添加sudo文件的写权限 chmod u+w /etc/sudoers 编辑sudoers文件 vim /etc/sudoers 找到root ALL=(ALL) ALL,在下面添加xxx ALL=(ALL) ALL (xxx即普通用户名) 撤销sudoers文件写权限 chmod u-w /etc/sudoers 这样普通用户就可以使用sudo命令了。 5.安装Chrome浏览器 虽然Debian自带了Firefox浏览器，但Firefox显然无法和Chrome浏览器相抗衡，亲测，在Debian和Ubuntu下，Firefox的打开速度都没有Chrome快，而且Firefox顶部有一个特别难看占面积的边框，果然放弃。 首先，打开终端并运行以下命令下载chrome deb包 wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb 然后，安装依赖关系 sudo apt install libappindicator1 libdbusmenu-glib4 libdbusmenu-gtk4 libindicator7 libpango1.0-0 libpangox-1.0-0 最后，使用dpkg安装chrome deb包 sudo dpkg -i google-chrome-stable_current_amd64.deb 安装过程中如果报错，可以使用一下命令 sudo apt-get update sudo apt-get upgrade sudo apt-get -f install 如果是缺包的话就安装呢相应的依赖包。 6.安装中文支持及搜狗输入法 要支持区域设置，首先要安装locales软件包 apt-get install locales 然后配置locales软件包 dpkg-reconfigure locales 在界面中选择zh_CN.UTF-8即可。 接下来就是中文输入法了，这里选择搜狗输入法，在官网下载deb包 sudo apt-get install fcitx sudo dpkg -i sougoupinyin_2.2.0.0108_amd64.deb 中间报错可以执行 sudo apt-get install -f sudo apt-get install update 安装过程中会出现各种各样的坑爹问题，一般来说都是可以解决的。 "},"docs/Linux/linux-change-file-permission.html":{"url":"docs/Linux/linux-change-file-permission.html","title":"Linux修改文件权限","keywords":"","body":"Linux系统下经常遇到文件或者文件夹的权限问题，或者是因为文件夹所属的用户问题而没有访问的权限。根据我自己遇到的情况，对这类问题做一个小结。 在命令行使用命令“ll”或者“ls -a”，可以查看文件或者文件的权限： -rw-r--r--. 1 root root 6 Nov 9 16:42 a.txt 其中“-rw-r--r--”表示权限，一共有十个字符。第一个字符，如果是“-”则表示是文件，如果是“d”则表示是目录（directory）。后面9个字符每3个字符又作为一个组，则有3组信息（“rw-”、“r--”、“r--”），分别表示所属用户本身具有的权限、所属用户的用户组其他成员的权限、其他用户的权限。 每一组信息如“rw-”,每一个字符都有它自己的特定含义且先后位置是固定的，其中r是读权限、w是写权限、x是可执行权限、-没有对应字符的权限。Linux里面对这些字符设置对应的数值，r是4，w是2，x是1，-是0。上面的“rw-”则是6（=4+2+0），所以最开始a.txt的权限是644，属于root用户组的root用户。 修改权限chmod 改文件的权限，我想修改文件a.txt的权限为755，则为： [root@master my]# ll -rw-r--r--. 1 root root 6 Nov 9 16:42 a.txt #改之前权限是644 [root@master my]# chmod 755 a.txt [root@master my]# ll -rwxr-xr-x. 1 root root 6 Nov 9 16:42 a.txt #改后权限是755 改文件夹的权限，改之前： [root@master test1]# ll drw-r--r--. 2 root root 4096 Nov 9 16:42 my #改之前文件夹my的权限是644 [root@master test1]# ll my/ -rwxr-xr-x. 1 root root 6 Nov 9 16:42 a.txt #改之前文件夹my的里面的文件权限是755 只改变文件夹本身权限，不改动子文件（夹），执行命令修改my文件夹权限为600： [root@master test1]# chmod 600 my/ #修改命令 [root@master test1]# ll drw-------. 2 root root 4096 Nov 9 16:42 my #改my文件夹之后权限是600 [root@master test1]# ll my/ -rwxr-xr-x. 1 root root 6 Nov 9 16:42 a.txt #改my文件夹之后里面的文件权限还是755，没有变化 改变文件夹及子目录下所有文件（夹）权限，执行1.2.1步骤之后，my文件夹和里面的文件权限都是不同的。现在递归修改，都改为统一的权限777： [root@master test1]# chmod -R 777 my/ #修改命令，注意中间是大写的R，不是小写 [root@master test1]# ll drwxrwxrwx. 2 root root 4096 Nov 9 16:42 my #修改后my文件夹权限是777 [root@master test1]# ll my/ -rwxrwxrwx. 1 root root 6 Nov 9 16:42 a.txt #修改后里面的文件变为了777 修改所属用户和用户组chown 这个和修改文件夹的权限是基本相同的，只不过是把chmod命令换成了chown。 修改文件所属用户和用户组，修改a.txt文件所属用户（jay）和用户组（fefjay）： chown jay:fefjay a.txt #修改文件所属用户为jay，所属用户组为fefjay 只改文件夹本身所属用户和用户组，不改子文件（夹），仅修改文件夹my本身所属用户（jay）和用户组（fefjay）： chown jay:fefjay my #修改文件所属用户为jay，所属用户组为fefjay 改变文件夹及所有子文件（夹）所属用户和用户组，递归修改文件夹my及包含的所有子文件（夹）的所属用户（jay）和用户组（fefjay）： chown -R jay:fefjay my #修改文件所属用户为jay，所属用户组为fefjay 总结 修改单个文件（夹）就用命令： chown或chmod “权限”或“名：组” 文件（夹）名称 修改文件夹及子文件夹所有文件就用命令： chown或chmod -R “权限”或“名：组” 文件夹名称 "},"docs/Linux/linux-file-catelog.html":{"url":"docs/Linux/linux-file-catelog.html","title":"Linux软件安装目录","keywords":"","body":" 文件类型 安装位置 用户自己的软件 /usr/local 普通执行程序文件 /usr/bin 服务器执行程序文件和管理程序文件 /usr/sbin 应用程序配置文件 /etc 日志文件 /var/log 应用程序文档文件 /usr/share/doc 应用程序手册页文件 /usr/share/man Linux 的软件安装目录是也是有讲究的，理解这一点，在对系统管理是有益的 /usr：系统级的目录，可以理解为C:/Windows/，/usr/lib理解为C:/Windows/System32。 /usr/local：用户级的程序目录，可以理解为C:/Progrem Files/。用户自己编译的软件默认会安装到这个目录下。 /opt：用户级的程序目录，可以理解为D:/Software，opt有可选的意思，这里可以用于放置第三方大型软件（或游戏），当你不需要时，直接rm -rf掉即可。在硬盘容量不够时，也可将/opt单独挂载到其他磁盘上使用。 源码放哪里？ /usr/src：系统级的源码目录。 /usr/local/src：用户级的源码目录 "},"docs/Linux/ubuntu-install-mysql.html":{"url":"docs/Linux/ubuntu-install-mysql.html","title":"Ubuntu安装MySql","keywords":"","body":"根据MySQL官方说明，在Debian/Ubuntu下安装MySQL很简单，只需要几条命令。首先下载Debian/Ubuntu MySQL APT repository，即APT支持包。 下载地址：https://dev.mysql.com/downloads/repo/apt/. 添加到系统software repository list sudo dpkg -i mysql-apt-config_0.8.10-1_all.deb 在安装软件包期间，系统会要求您选择要安装的MySQL服务器版本和其他组件（例如，MySQL Workbench）。 如果您不确定选择哪个版本，请不要更改为您选择的默认选项。 如果您不想安装特定组件，也可以选择none。 在为所有组件做出选择后，选择“确定”以完成发布包的配置和安装。 更新APT repository sudo apt-get update 安装MySQL sudo apt-get install mysql-server sudo apt-get install mysql-client sudo apt-get install libmysqlclient-dev 安装过程中会要求为mysql的root用户设置密码 然后就可以开始/停止MySQL服务了 sudo service mysql status sudo service mysql stop sudo service mysql start 登录MySQL数据库 mysql -u root -p 登录后可以用一下命令导入备份好的数据库 source /home/liuning/Documents/mysqlbackup/mybatis.sql 可以选择安装mysql-workbench-community sudo apt-get install mysql-workbench-community 安装的时候可能会报错，可以先从官网下载deb包在用dpkg安装。 下载地址：https://dev.mysql.com/downloads/workbench/ "},"docs/Linux/ubuntu-zip-chinese-error-code.html":{"url":"docs/Linux/ubuntu-zip-chinese-error-code.html","title":"butnu解决zip中文乱码问题","keywords":"","body":"Ubuntu自带的解压工具zip解压的时候总是中文乱码，使用unar工具可以完美地解决zip解压乱码问题，操作也很简单，一步到位。 安装unar解压工具 sudo apt-get install unar 解压相应的zip文件 unar document.zip 瞬间就能解决zip解压中文乱码的问题。 "},"docs/Linux/ubuntu18.04-install-jdk.html":{"url":"docs/Linux/ubuntu18.04-install-jdk.html","title":"Ubuntu18.04安装jdk","keywords":"","body":"这两天由于公司发了新电脑，加上对Windows不满已久，于是给旧电脑装了个Ubuntu 18.04 LTS。之前装的Windows和Elementary OS双系统算是放弃了。 发现Ubuntu对就电脑也并不是那么友好，对资源使用率和Windows不相上下，算是入坑了。 首当其冲给Ubuntu装上jdk1.8.0_171，由于以前Linux用得不是很多，这里记录一下，方便以后折腾。 官网下载JDK文件jdk-8u171-linux-x64.tar.gz 下载地址 在/opt创建一个目录作为JDK的安装目录，我的目录为/opt/java sudo mkdir /opt/java 下载好的JDK文件一般在Downloads目录下，需要将其移动到/opt/java下，Ctrl+Alt+T打开终端 cd Downloads sudo mv jdk-8u171-linux-x64.tar.gz /opt/java 切换到/opt/java目录下，解压文件。这里同样需要管理员权限 cd /opt/java sudo tar -zxvf jdk-8u171-linuc-x64.tar.gz 解压完成后需要配置环境变量 sudo vim /etc/profile 在文件的最后添加以下内容 #set Java environment export JAVA_HOME=/opt/java/jdk1.8.0_171 export JRE_HOME=$JAVA_HOME/jre export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH 上面的JAVA_HOME就是安装JDK的目录 使用命令使环境变量立即生效 source /etc/profile java -version -java version \"1.8.0_171\" -Java(TM) SE Runtime Environment (build 1.8.0_171-b11) -Java HotSpot(TM) 64-Bit Server VM (build 25.171-b11, mixed mode) 显示JDK版本则说明环境变量配置成功。有时候可能需要重启一下电脑。 "},"docs/Tools/":{"url":"docs/Tools/","title":"编程工具","keywords":"","body":"Summary git stash详解 git使用简单总结 玩转Intellij IDEA Tomcat部署常用命令 "},"docs/Tools/git-stash.html":{"url":"docs/Tools/git-stash.html","title":"git stash详解","keywords":"","body":"应用场景： 1.当正在dev分支上开发某个项目，这时项目中出现一个bug，需要紧急修复，但是正在开发的内容只是完成一半，还不想提交，这时可以用git stash命令将修改的内容保存至堆栈区，然后顺利切换到hotfix分支进行bug修复，修复完成后，再次切回到dev分支，从堆栈中恢复刚刚保存的内容。 2.由于疏忽，本应该在dev分支开发的内容，却在master上进行了开发，需要重新切回到dev分支上进行开发，可以用git stash将内容保存至堆栈中，切回到dev分支后，再次恢复内容即可。 总的来说，git stash命令的作用就是将目前还不想提交的但是已经修改的内容进行保存至堆栈中，后续可以在某个分支上恢复出堆栈中的内容。这也就是说，stash中的内容不仅仅可以恢复到原先开发的分支，也可以恢复到其他任意指定的分支上。 git stash作用的范围包括工作区和暂存区中的内容，也就是说没有提交的内容都会保存至堆栈中。 命令详解： git stash 能够将所有未提交的修改（工作区和暂存区）保存至堆栈中，用于后续恢复当前工作目录。 git stash save 作用等同于git stash，区别是可以加一些注释 git stash list 查看当前stash中的内容 git stash pop 将当前stash中的内容弹出，并应用到当前分支对应的工作目录上。 注：该命令将堆栈中最近保存的内容删除（栈是先进后出） 如果从stash中恢复的内容和当前目录中的内容发生了冲突，也就是说，恢复的内容和当前目录修改了同一行的数据，那么会提示报错，需要解决冲突，可以通过创建新的分支来解决冲突。 git stash apply 将堆栈中的内容应用到当前目录，不同于git stash pop，该命令不会将内容从堆栈中删除，也就说该命令能够将堆栈的内容多次应用到工作目录中，适应于多个分支的情况。 堆栈中的内容并没有删除。 可以使用git stash apply + stash名字（如stash@{1}）指定恢复哪个stash到当前的工作目录。 git stash clear 清除堆栈中的所有 内容 git stash show 查看堆栈中最新保存的stash和当前目录的差异。 "},"docs/Tools/git.html":{"url":"docs/Tools/git.html","title":"git使用简单总结","keywords":"","body":"新建分支 git branch 例如新建dev分支并将其推送到远程仓库 git branch dev git checkout dev git push --set-upstream origin dev 其中git checkout dev命令从master、分支切换到dev分支. 如果出现下面的错误 fatal: No destination configured to pus to. 说明缺少推送的目标地址，解决方法有两种 添加目标地址参数 git push git@github.com:xxx/xxx.git 设置默认参数 git remote add origin git@github.com:xxx/xxx.git git push 查看当前所有分支信息git branch -av 用户名和邮箱地址 查看 git config user.name git config user.email 修改 git config --global user.name \"username\" git config --global user.email \"email\" 配置ssh key 打开终端，输入 ssh-keygen -t rsa -C 'xxxx@xxx.com' 根据提示输入密码，一路回车，会在用户文件夹的.ssh下生成三个文件：id_rsa id_rsa.pub knowm_hosts 进入Github个人主页--settings--点击SSH and GPG keys 打开id_rsa.pub，将其中的内容复制到github的ssh key 输入框里面 之后就可以正常的用git来同步开发项目了。 创建完仓库之后，将本地项目和该仓库关联的步骤： ①先cd到本地项目的文件夹，执行：git init ②添加自述文件：git add README.md add所有的文件 $ git add -u ③将代码提交到本地仓库先 ：git commit -m \"first commit\" //“”是注释，任意写 ④ 将本地项目和远程仓库关联： git remote add origin https://github.com/xxx(一般是你的邮箱名）/xxx（仓库名称）.git 将本地项目和远程项目进行合并 $ git pull --rebase origin master ⑤将本地代码push到远程仓库： git push -u origin master 把远程仓库的代码合并到本地仓库，但不会提交本地的代码 $ git pull : 因为已经和远程仓库关联，因此用origin代替远程主机名 $ git pull origin Branch.v0.1.1828_dev:Branch.v0.1.1828_dev push的时候如果暴力一点可以直接 $ git push 清除本地分支 Git如果在远程仓库上删除了某一分支，并不会删除本地的远程追踪分支。这时候，可以使用如下命令查看那些分支需要清理： $ git remote prune origin --dry-run Pruning origin URL: git@10.2.10.22:xxx/xxx.git * [would prune] origin/Branch.v1.0.1908 * [would prune] origin/Branch_dev_bugfix_merchant_h5 可以看到，有两个远程分支已经失效，将会被清理，执行 $ git remote prune origin 这样，就完成了无效的远程追踪分支的清理工作。 需要注意，这里远程追踪分支批位于.git/refs/remote/origin 下的分支，如果有本地分支被check out的话，还需要手动清理 $ git branch -vv Branch.v1.0.1908_unionpay [origin/Branch.v1.0.1908_unionpay: gone] 无效的远程追踪分支会以gone来标识 删除无效的本地分支命令: $ git branch -d Branch.v1.0.1908_unionpay 添加Tag 打印所有标签 $ git tag 查看对应标签状态 $ git checkout 附注标签是一个独立的标签对象，包含了名称时间戳以及标签备注等信息，同时指向对应的commit，定义方法如下： $ git tag -a -m \"\" 删除本地标签 $ git tag -d 同创建本地标签一样，删除了本地标签之后也要同时删除远程仓库的标签 $ git push origin --delete 推送本地标签到远程仓库 $ git push origin --tags 推送指定版本的标签 $ git push origin "},"docs/Tools/Intellij-idea-keymap.html":{"url":"docs/Tools/Intellij-idea-keymap.html","title":"玩转Intellij IDEA","keywords":"","body":"无处不在的跳转 项目之间跳转：option+command+` 最近的文件(Recent Files)：command+E(Ctrl+E) 最近改变的文件：shift+command+E 跳转到上次修改的地方：shift+command+backspace(Ctrl+Shift+Backspace) 上次浏览的地方：option+command+L(Ctrl+Alt+L)，下一次浏览的地方option+command+R(Ctrl+Alt+L) 精准搜索 搜索类(Go to class)：command+O(Ctrl+N)，可以选择包含jar包中所有的类 搜索文件(Go to file)：shift+command+O(Ctrl+Shift+N) 根据符号搜索(Go to symbol)：option+command+O(Ctrl+Shift+Alt+N) double shift可以快速地根据类、文件、符号搜索 根据字符串搜索(Find in path)：shift+command+F(Ctrl+Shift+F)，比较常用，可以选择是否匹配大小写、字符串是否是个单词、通过正则表达式搜索、指定在哪类文件搜索，还可以选择搜索范围 在当前文件中搜索：command+F(Ctrl+F) Alt+Enter alt+enter虽然只是一个简单的快捷键，但是却拥有极其强大的功能。 自动创建函数 list replace，即当写了一个传统for循环后，alt+enter会帮你自动转换成for-in循环 字符串format或者build 单词拼写 倒入依赖 重构 当需要对某个变量统一修改时，将光标移到变量名称上，shift+F6就可以快速修改 command+F6修改函数签名(Change Signature)，可以对函数名称、返回值、参数等进行修改 Ctrl+Alt+L 格式化代码 Ctrl+Alt+O 优化导入的类和包 Alt+Insert 生成代码(如get,set方法,构造函数等) Ctrl+E或者Alt+Shift+C 最近更改的代码 Ctrl+R 替换文本 Ctrl+Shift+Space 自动补全代码 Ctrl+空格 代码提示 Ctrl+Alt+Space 类名或接口名提示 Ctrl+P 方法参数提示 Ctrl+Shift+Alt+N 查找类中的方法或变量 Alt+Shift+C 对比最近修改的代码 Shift+F6 重构-重命名 Ctrl+Shift+先上键 Ctrl+X 删除行 Ctrl+D 复制行 Ctrl+/ 或 Ctrl+Shift+/ 注释（// 或者/.../ ） Ctrl+J 自动代码 Ctrl+E 最近打开的文件 Ctrl+H 显示类结构图 Ctrl+Q 显示注释文档 Alt+F1 查找代码所在位置 Alt+1 快速打开或隐藏工程面板 Ctrl+Alt+ left/right 返回至上次浏览的位置 Alt+ left/right 切换代码视图 Alt+ Up/Down 在方法间快速移动定位 Ctrl+Shift+Up/Down 代码向上/下移动。 F2 或Shift+F2 高亮错误或警告快速定位 代码标签输入完成后，按Tab，生成代码。 选中文本，按Ctrl+Shift+F7 ，高亮显示所有该文本，按Esc高亮消失。 Ctrl+W 选中代码，连续按会有其他效果 选中文本，按Alt+F3 ，逐个往下查找相同文本，并高亮显示。 Ctrl+Up/Down 光标跳转到第一行或最后一行下 Ctrl+B 快速打开光标处的类或方法 最常用快捷键 1.Ctrl＋E，可以显示最近编辑的文件列表 2.Shift＋Click可以关闭文件 3.Ctrl＋[或]可以跳到大括号的开头结尾 4.Ctrl＋Shift＋Backspace可以跳转到上次编辑的地方 5.Ctrl＋F12，可以显示当前文件的结构 6.Ctrl＋F7可以查询当前元素在当前文件中的引用，然后按F3可以选择 7.Ctrl＋N，可以快速打开类 8.Ctrl＋Shift＋N，可以快速打开文件 9.Alt＋Q可以看到当前方法的声明 10.Ctrl＋W可以选择单词继而语句继而行继而函数 11.Alt＋F1可以将正在编辑的元素在各个面板中定位 12.Ctrl＋P，可以显示参数信息 13.Ctrl＋Shift＋Insert可以选择剪贴板内容并插入 14.Alt＋Insert可以生成构造器/Getter/Setter等 15.Ctrl＋Alt＋V 可以引入变量。例如把括号内的SQL赋成一个变量 16.Ctrl＋Alt＋T可以把代码包在一块内，例如try/catch 17.Alt＋Up and Alt＋Down可在方法间快速移动 下面的不是很有用 18.在一些地方按Alt＋Enter可以得到一些Intention Action，例如将”==”改为”equals()” 19.Ctrl＋Shift＋Alt＋N可以快速打开符号 20.Ctrl＋Shift＋Space在很多时候都能够给出Smart提示 21.Alt＋F3可以快速寻找 22.Ctrl＋/和Ctrl＋Shift＋/可以注释代码 23.Ctrl＋Alt＋B可以跳转到抽象方法的实现 24.Ctrl＋O可以选择父类的方法进行重写 25.Ctrl＋Q可以看JavaDoc 26.Ctrl＋Alt＋Space是类名自动完成 27.快速打开类/文件/符号时，可以使用通配符，也可以使用缩写 28.Live Templates! Ctrl＋J 29.Ctrl＋Shift＋F7可以高亮当前元素在当前文件中的使用 30.Ctrl＋Alt＋Up /Ctrl＋Alt＋Down可以快速跳转搜索结果 31.Ctrl＋Shift＋J可以整合两行 32.Alt＋F8是计算变量值 IntelliJ IDEA使用技巧一览表 在使用 InelliJ IDEA 的过程中，通过查找资料以及一些自己的摸索，发现这个众多 Java 程序员喜欢的 IDE 里有许多值得一提的小窍门，如果能熟练的将它们应用于实际开发过程中，相信它会大大节省你的开发时间，而且随之而来的还会有那么一点点成就感：） Try it ！ 1 、写代码时用 Alt-Insert （ Code|Generate… ）可以创建类里面任何字段的 getter 与 setter 方法。 2 、右键点击断点标记（在文本的左边栏里）激活速查菜单，你可以快速设置 enable/disable 断点或者条件它的属性。 3 、 CodeCompletion （代码完成）属性里的一个特殊的变量是，激活 Ctrl-Alt-Space 可以完成在或不在当前文件里的类名。如果类没有引入则 import 标志会自动创建。 4 、使用 Ctrl-Shift-V 快捷键可以将最近使用的剪贴板内容选择插入到文本。使用时系统会弹出一个含有剪贴内容的对话框，从中你可以选择你要粘贴的部分。 5 、利用 CodeCompletion （代码完成）属性可以快速地在代码中完成各种不同地语句，方法是先键入一个类名地前几个字母然后再用 Ctrl-Space 完成全称。如果有多个选项，它们会列在速查列表里。 6 、用 Ctrl-/ 与 Ctrl-Shift-/ 来注释 / 反注释代码行与代码块。 -/ 用单行注释标记（“ //… ”）来注释 / 反注释当前行或者选择地代码块。而 Ctrl-Shift-/ 则可以用块注释标记（“ /…/ ”）把所选块包围起来。要反注释一个代码块就在块中任何一个地方按 Ctrl-Shift-/ 即可。 7 、按 Alt-Q （ View|Context Info ）可以不需要移动代码就能查看当前方法地声明。连续按两次会显示当前所编辑的类名。 8 、使用 Refactor|Copy Class… 可以创建一个所选择的类的“副本”。这一点很有用，比如，在你想要创建一个大部分内容都和已存在类相同的类时。 9 、在编辑器里 Ctrl-D 可以复制选择的块或者没有所选块是的当前行。 10 、 Ctrl-W （选择字）在编辑器里的功能是先选择脱字符处的单词，然后选择源代码的扩展区域。举例来说，先选择一个方法名，然后是调用这个方法的表达式，然后是整个语句，然后包容块，等等。 11 、如果你不想让指示事件细节的“亮球”图标在编辑器上显示，通过按 Alt-Enter 组合键打开所有事件列表然后用鼠标点击它就可以把这个事件文本附件的亮球置成非活动状态。 这样以后就不会有指示特殊事件的亮球出现了，但是你仍然可以用 Alt-Enter 快捷键使用它。 12 、在使用 CodeCompletion 时，可以用逗点（ . ）字符，逗号（，）分号（；），空格和其它字符输入弹出列表里的当前高亮部分。选择的名字会随着输入的字符自动输入到编辑器里。 13 、在任何工具窗口里使用 Escape 键都可以把焦点移到编辑器上。 Shift-Escape 不仅可以把焦点移到编辑器上而且还可以隐藏当前（或最后活动的）工具窗口。 F12 键把焦点从编辑器移到最近使用的工具窗口。 14 、在调试程序时查看任何表达式值的一个容易的方法就是在编辑器中选择文本（可以按几次 Ctrl-W 组合键更有效地执行这个操作）然后按 Alt-F8 。 15 、要打开编辑器脱字符处使用的类或者方法 Java 文档的浏览器，就按 Shift-F1 （右键菜单的 External JavaDoc ）。 要使用这个功能须要把加入浏览器的路径，在“ General ”选项中设置（ Options | IDE Settings ），另外还要把创建的 Java 文档加入到工程中（ File | Project Properties ）。 16 、用 Ctrl-F12 （ View | File Structure Popup ）键你可以在当前编辑的文件中快速导航。 这时它会显示当前类的成员列表。选中一个要导航的元素然后按 Enter 键或 F4 键。要轻松地定位到列表中的一个条目，只需键入它的名字即可。 17 、在代码中把光标置于标记符或者它的检查点上再按 Alt-F7 （右键菜单中的 Find Usages… ）会很快地查找到在整个工程中使用地某一个类、方法或者变量的位置。 18 、按 Ctrl-N （ Go to | Class… ）再键入类的名字可以快速地在编辑器里打开任何一个类。从显示出来的下拉列表里选择类。 同样的方法你可以通过使用 Ctrl-Shift-N （ Go to | File… ）打开工程中的非 Java 文件。 19 、要导航代码中一些地方使用到的类、方法或者变量的声明，把光标放在查看项上再按 Ctrl-B 即可。也可以通过按 Ctrl 键的同时在查看点上单击鼠标键调转到声明处。 20 、把光标放到查看点上再按 Ctrl-Alt-B 可以导航到一个抽象方法的实现代码。 21 、要看一个所选择的类的继承层次，按 Ctrl-H （ Browse Type Hierarchy ）即可。也可以激活编辑器中的继承关系视图查看当前编辑类的继承关系。22 、使用 Ctrl-Shift-F7 （ Search | Highlight Usages in File ）可以快速高亮显示当前文件中某一变量的使用地方。按 Escape 清除高亮显示。 23 、用 Alt-F3 （ Search | Incremental Search ）在编辑器中实现快速查查找功能。 在“ Search for: ”提示工具里输入字符，使用箭头键朝前和朝后搜索。按 Escape 退出。 24 、按 Ctrl-J 组合键来执行一些你记不起来的 Live Template 缩写。比如，键“ it ”然后按 Ctrl-J 看看有什么发生。 25 、 Introduce Variable 整合帮助你简化代码中复杂的声明。举个例子，在下面的代码片断里，在代码中选择一个表达式：然后按 Ctrl-Alt-V 。 26 、 Ctrl-Shift-J 快捷键把两行合成一行并把不必要的空格去掉以匹配你的代码格式。 27 、 Ctrl-Shift-Backspace （ Go to | Last Edit Location ）让你调转到代码中所做改变的最后一个地方。 多按几次 Ctrl-Shift-Backspace 查看更深的修改历史。 28 、用 Tools | Reformat Code… 根据你的代码样式参考（查看 Options | IDE Setting | Code Style ）格式化代码。 使用 Tools | Optimize Imports… 可以根据设置（查看 Options | IDE Setting | Code Style | Imports ）自动“优化” imports （清除无用的 imports 等）。 29 、使用 IDEA 的 Live Templates | Live Templates 让你在眨眼间创建许多典型代码。比如，在一个方法里键入 再按 Tab 键看有什么事情发生了。 用 Tab 键在不同的模板域内移动。查看 Options | Live Templates 获取更多的细节。 30 、要查看一个文件中修改的本地历史，激活右键菜单里的 Local VCS | Show History… 。也许你可以导航不同的文件版本，看看它们的不同之处再回滚到以前的任何一个版本吧。 使用同样的右键菜单条目还可以看到一个目录里修改的历史。有了这个特性你就不会丢失任何代码了。 31 、如果要了解主菜单里每一个条目的用途，把鼠标指针移到菜单条目上再应用程序框架的底部的状态栏里就会显示它们的一些简短描述，也许会对你有帮助。 32 、要在编辑器里显示方法间的分隔线，打开 Options | IDE Settings | Editor ，选中“ Show method separators ”检查盒（ checkbox ）。 33 、用 Alt-Up 和 Alt-Down 键可以在编辑器里不同的方法之间快速移动。 34 、用 F2/Shift-F2 键在高亮显示的语法错误间跳转。 用 Ctrl-Alt-Down/Ctrl-Alt-Up 快捷键则可以在编译器错误信息或者查找操作结果间跳转。 35 、通过按 Ctrl-O （ Code | Override Methods… ）可以很容易地重载基本类地方法。 要完成当前类 implements 的（或者抽象基本类的）接口的方法，就使用 Ctrl-I （ Code | Implement Methods… ）。 36 、如果光标置于一个方法调用的括号间，按 Ctrl-P 会显示一个可用参数的列表。 37 、要快速查看编辑器脱字符处使用的类或方法的 Java 文档，按 Ctrl-Q （在弹出菜单的 Show Quick JavaDoc 里）即可。 38 、像 Ctrl-Q （ Show Quick JavaDoc 显示简洁 Java 文档）， Ctrl-P （ Show Parameter Info 显示参数信息）， Ctrl-B （ Go to Declaration 跳转到声明）， Shift-F1 （ External JavaDoc 外部 Java 文档）以及其它一些快捷键不仅可以在编辑器里使用，也可以应用在代码完成右键列表里。 39 、 Ctrl-E （ View | Recent Files ）弹出最近访问的文件右键列表。选中文件按 Enter 键打开。 40 、在 IDEA 中可以很容易地对你的类，方法以及变量进行重命名并在所有使用到它们的地方自动更正。 试一下，把编辑器脱字符置于任何一个变量名字上然后按 Shift-F6 （ Refactor | Rename… ）。在对话框里键入要显示地新名字再按 Enter 。你会浏览到使用这个变量地所有地方然后按“ Do Refactor ”按钮结束重命名操作。 41 、要在任何视图（ Project View 工程视图， Structure View 结构视图或者其它视图）里快速 选择当前编辑地部分（类，文件，方法或者字段），按 Alt-F1 （ View | Select in… ）。 42 、在“ new ”字符后实例化一个已知类型对象时也许你会用到 SmartType 代码完成这个特性。比如，键入 再按 Ctrl-Shift-Space ： 43 、通过使用 SmartType 代码完成，在 IDEA 中创建接口的整个匿名 implementation 也是非常容易的，比如，对于一些 listener （监听器），可以键入 Component component; component.addMouseListener( new ); 然后再按 Ctrl-Shift-Space 看看有什么发生了。 44 、在你需要设置一个已知类型的表达式的值时用 SmartType 代码完成也很有帮助。比如，键入 String s = ( 再按 Ctrl-Shift-Space 看看会有什么出现。 45 、在所有视图里都提供了速查功能：在树里只需键入字符就可以快速定位到一个条目。 46 、当你想用代码片断捕捉异常时，在编辑器里选中这个片断，按 Ctrl-Alt-T （ Code | Surround with… ）然后选择“ try/catch ”。它会自动产生代码片断中抛出的所有异常的捕捉块。在 Options | File Templates | Code tab 中你还可以自己定制产生捕捉块的模板。 用列表中的其它项可以包围别的一些结构。 47 、在使用代码完成时，用 Tab 键可以输入弹出列表里的高亮显示部分。 不像用 Enter 键接受输入，这个选中的名字会覆盖掉脱字符右边名字的其它部分。这一点在用一个方法或者变量名替换另一个时特别有用。 48 、在声明一个变量时代码完成特性会给你显示一个建议名。比如，开始键入“ private FileOutputStream ”然后按 Ctrl-Space "},"docs/Tools/tomcat-deploy-command.html":{"url":"docs/Tools/tomcat-deploy-command.html","title":"Tomcat部署常用命令","keywords":"","body":"部署 一般情况下进入 /bin 路径下shutdown.sh关闭 ./shutdown.sh 有时候关闭失败需要手动杀掉进程，查看tomcat所有进程 ps -ef|grep tomcat 关闭tomcat进程 kill -9 pid 然后将war包放入 /webapps 路径下，重新启动即可 ./startup.sh 查看端口号8080运行的程序: lsof -i :8080 查看日志 tail命令用于依照要求将指定的文件的最后部分输出到标准设备，通常是终端，假设该文件有更新，tail会自己主动刷新，确保看到的是最新内容。 在 /logs 下查看tomcat启动日志: tail -f catalina.out 查看最后100行日志信息: tail -100f catalina.out 查看最后100行日志信息，但不刷新 tail -n 100 catalina.out 根据关键词字符串查看相关日志 tail -f catalina.out | grep \"053574ccc432403c9762ac1372a7c7\" "},"docs/Reprint/":{"url":"docs/Reprint/","title":"转载","keywords":"","body":"Summary 一个从阿里面试回来的程序员的感想 用十年来学编程 从Intel和ARM争霸战，看看做芯片有多难 Ajxa已死，fetch永生 "},"docs/Reprint/Alibaba.html":{"url":"docs/Reprint/Alibaba.html","title":"一个从阿里面试回来的程序员的感想","keywords":"","body":"引言 其实本来真的没打算写这篇文章，主要是LZ得记忆力不是很好，不像一些记忆力强的人，面试完以后，几乎能把自己和面试官的对话都给记下来。LZ自己当初面试完以后，除了记住一些聊过的知识点以外，具体的内容基本上忘得一干二净，所以写这篇文章其实是很有难度的。 但是，最近问LZ的人实在是太多了，为了避免重复回答，给自己省点力气，干脆就在这里统一回复了。 其实之前LZ写过一篇文章，但是那篇文章更多的是在讨论“面试前该不该刷题”这个话题，而这篇文章将会更加聚焦在面试前如何准备，以及工作当中如何学习这个话题上，而且会尽量写出一些干货。 阿里面试都问什么 这个是让LZ最头疼的一个问题，也是群里的猿友们问的最多的一个问题。说实话，LZ只能隐约想起并发、JVM、分布式、TCP/IP协议这些个关键字，具体的问题真的是几乎都没记住。而且就算LZ记住了，也告诉你了，你也背会了，但LZ觉得，在面试中，你被问到一模一样问题的可能性依然很小。甚至，就算你运气好被问到了，你也照着背下来了，也不一定就能对你的面试起到正面的作用，因为面试官万一多问一句，你可能就露馅了，那还不如干脆点说不会更好。 LZ参加的是阿里的社招面试，而社招不同于校招，问题的范围其实是很随机的。因为能参加一些比较知名的互联网公司社招的人，70%以上都会有个3-5年的经验。这倒不是说一两年经验的同学没有机会进这些公司，而是因为这种公司，大部分情况下只招一些比较资深的开发和应届生，而不招那些处于中间阶段的人。而1-2年经验的同学，往往就刚好处于这个尴尬的阶段。 对于能有3-5年经验的这部分人中，每个人的经历又都不同，所擅长的点也不一样，因此这就会导致每个人的问题和范围都不太一样。很少说有哪个知名的互联网公司，比如BAT、京东、360、搜狐、网易等这些公司，其社招面试还有固定的问题和模式，让你可以像应届生面试一样，在面试前靠临时抱佛脚度过这一关。 大部分公司在社招的时候，不光是阿里，其它公司也都一样（因为LZ在一年多前也参加过很多其它知名互联网公司的面试，基本上都分为两个阶段的提问。 第一个阶段是主语言本身以及它的高级特性，第二个阶段是讲述自己的项目，并在中间穿插着问题。 所以，LZ不妨就这两个阶段，谈谈社招面试的准备，而不是去把阿里面试的过程背一遍。说实话，LZ也确实记不住，所以不要再问LZ阿里面试都会问哪些问题了，你看看上面那个连接里的文章，也会发现，LZ里面也基本上没有写具体的问题，原因是一样的，真的记不住啊。 社招面试如何准备 LZ会分为四个部分来谈论这个问题，由于LZ本身是Java出身，因此关于主语言的问题，都是与Java相关，其它语言的同学可以选择性忽略。此外，面试的时候一般面试官的问题都是环环相扣，逐渐深入的，这点在下面大家可以更明显的感受出来。 1.主语言本身以及它的高级特性 主语言当然就是你平日里拿来赚钱的家伙。不要告诉LZ你没有主语言，你会N多种语言，或者是你精通N多种语言，你要非这么说的话，你可以来杭州试试，LZ保证不打死你，最多打残。LZ的主语言很显然是Java，那么对于Java来说，它的语言本身以及它的高级特性，都有哪些比较容易在面试中问到呢？ 一般情况下，主要有以下知识点很容易被问到。（PS：以下所列举的，都是一些Java相对而言比较高级一点的知识点，因为这里谈的是社招，而不是校招） 1）Java的数据结构相关的类实现原理，比如LinkedList，ArrayList，HashMap，TreeMap这一类的。以下简单模拟一个数据结构的连环炮。比如，面试官先问你HashMap是不是有序的？ 你肯定回答说，不是有序的。那面试官就会继续问你，有没有有顺序的Map实现类？ 你如果这个时候说不知道的话，那这个问题就到此结束了。如果你说有TreeMap和LinkedHashMap。那么面试官接下来就可能会问你，TreeMap和LinkedHashMap是如何保证它的顺序的？ 如果你回答不上来，那么到此为止。如果你依然回答上来了，那么面试官还会继续问你，你觉得它们两个哪个的有序实现比较好？ 如果你依然可以回答的话，那么面试官会继续问你，你觉得还有没有比它更好或者更高效的实现方式？ 如果你还能说出来的话，那么就你所说的实现方式肯定依然可以问你很多问题。 以上就是一个面试官一步一步提问的例子。所以，如果你了解的不多，千万不要敷衍，因为可能下一个问题你就暴露了，还不如直接说不会，把这个问题结束掉，赶紧切换到你熟悉的领域。 2）Java并发包当中的类，它们都有哪些作用，以及它们的实现原理，这些类就是java.concurrent包下面的。与上面一样，咱们也简单的模拟一个并发包的连环炮。比如面试官可能会先问你，如果想实现所有的线程一起等待某个事件的发生，当某个事件发生时，所有线程一起开始往下执行的话，有什么好的办法吗？ 这个时候你可能会说可以用栅栏（Java的并发包中的CyclicBarrier），那么面试官就会继续问你，你知道它的实现原理吗？ 如果你继续回答的话，面试官可能会继续问你，你还知道其它的实现方式吗？ 如果你还能说出很多种实现方式的话，那么继续问你，你觉得这些方式里哪个方式更好？ 如果你说出来某一个方式比较好的话，面试官依然可以继续问你，那如果让你来写的话，你觉得还有比它更好的实现方式吗？ 如果你这个时候依然可以说出来你自己更好的实现方式，那么面试官肯定还会揪着这个继续问你。 为什么说面试的时候要引导面试官，原因就在这了。因为面试官的提问很多时候都是有迹可循的，你如果抓住了他的轨迹，能够猜到他下面很可能会问什么，那你在回答的时候就可以往你想要谈的方向去说。这样面试时就会显得更加从容，更加的游刃有余。 3）IO包和NIO包中的内容。这部分里面NIO会是重点，IO包大部分都会比较熟悉，因此可能会直接略过，直接问你NIO的内容。IO包和NIO包的内容相对来说不是很多，首先NIO模型要熟悉，特别是其中的selector一定要非常清楚它的职责和实现原理。其实NIO的核心是IO线程池，一定要记住这个关键点。有的时候，面试官可能也会问你IO包的设计模式（装饰器模式），为什么要这样设计？ 有的面试官还会问你有没有更好的设计，这个时候如果你不知道请果断说自己现在的水平有限，想不出来更好的设计，千万不要信口开河，随意YY。 4）Java的虚拟机的内容。这部分主要包括三部分，GC、类加载机制，以及内存。 面试官可以先问你什么时候一个对象会被GC？ 接着继续问你为什么要在这种时候对象才会被GC？ 接着继续问你GC策略都有哪些分类？ 你如果说出来了，继续问你这些策略分别都有什么优劣势？都适用于什么场景？ 你继续说出来了以后，给你举个实际的场景，让你选择一个GC策略？ 你如果选出来了，继续问你，为什么要选择这个策略？ 5）下面是关于类加载机制的简单连环炮。 首先肯定是先问你Java的类加载器都有哪些？ 回答了这些以后，可能会问你每个类加载器都加载哪些类？ 说完以后，可能会问你这些类加载之间的父子关系是怎样的？ 你在回答的时候可能会提到双亲委派模型，那么可以继续问你什么是双亲委派模型？ 你解释完了以后，可能会继续问你，为什么Java的类加载器要使用双亲委派模型？ 你回答完以后，可能会继续问你如何自定义自己的类加载器，自己的类加载器和Java自带的类加载器关系如何处理？ 6）再来一个关于内存的连环炮。 首先肯定就是问你内存分为哪几部分，这些部分分别都存储哪些数据？ 然后继续问你一个对象从创建到销毁都是怎么在这些部分里存活和转移的？ 接着可能会问你，内存的哪些部分会参与GC的回收？ 完事以后，可能还会问你Java的内存模型是怎么设计的？ 你回答了以后，还会继续问你为什么要这么设计？ 问完以后，还可能会让你结合内存模型的设计谈谈volatile关键字的作用？ 你在谈的时候，肯定会提到可见性，那么接着可见性这三个字，还可以继续问你并发的内容。 基本上Java语言本身以及语言稍微高级点的内容就是以上部分，如果你能把以上四部分了解的非常透彻，那基本上Java这部分就没啥问题了，因为光以上的内容就够你跟面试官聊很久了。你聊这些聊得久了，自然问你其它问题的时间就会短点。你从LZ写这些问题的过程也应该能感受出来，很多时候，面试官都是顺着一条线一路问下去的，如果你觉得这条线你不熟悉的话，就要及时拐弯，引导面试官去问其它方面的问题。千万不要一直往下深入，直到自己跳不出来为止，那就尴了个尬了。 2、讲述自己的项目，并在中间穿插着问题 这一部分是面试过程中必问，也是聊得最久的一个阶段。除非你前面的语言部分非常扎实，扎实到面试官问了一两个小时，依旧没有探出你对语言本身的了解到底有多深。否则的话，你一定逃不过自己的项目这一关，而且一般情况下聊得时间不会太短。 这一部分内容，一般的模式就是你自己去讲你做过的项目，然后面试官会冷不丁的让你去解释其中某一部分，比如让你解释当时为什么要这么做，或者问你现在觉得有没有更好的办法。而这些穿插的问题，大部分与你的项目所用到的技术有关。而你需要做的，就是充分、再充分的去总结自己做过的项目（尤其是最近的一两个项目），挖掘出一个甚至N个亮点，以备于到时候可以让面试官产生眼前一亮的感觉。如果你能达到这种效果的话，基本上离你成功就不远了。 这部分内容由于和每个人自己的经历息息相关，因此这里也没法列举可能问到的问题。 3、额外的加分项 上面两个阶段基本上是必问的，还有一些加分项。这些加分项中，有些内容面试官也会问你（比如TCP/IP协议、算法），但更多的是会先问你了解不了解，你了解的话再继续聊，不了解的话就直接略过了，不至于因为这种问题而直接把你打入地狱。 下面LZ列举一下这些加分项，如果可以的话，这些加分项还是要争取一下的。 计算机系统原理。 网络通信协议（TCP/IP，HTTP等）。 数据结构与算法。 著名开源项目的源码。 你自己有很棒的开源项目。 你的个人博客。 待评论区补充。 这几项当中，对于前1-3项，如果你之前就比较了解，只是由于时间问题忘记了的话，还是可以临时抱佛脚一下的。至于后面4-6项，就需要你日常的积累了，不是一时半会儿能做到的。如果你平日里没有积累，那么后面这三个加分项只能抛弃了。 4、与你职位相关的内容 其实这最后一项是对前面三项的补充，你应该尽量去主攻和你面试的职位相关的内容。比如你面试一个实时计算的职位，那么你的算法最好要厉害，对于著名的实时计算开源项目要熟悉，最好阅读过源码，而且还要对分布式系统有一定的见解。 因此，这个第4部分没有具体的内容，只是提醒你，如果你很明确自己的面试职位，最好在面试前准备的时候，尽量朝职位的需求方向靠拢，这样成功的可能性更大。 对于Java程序猿学习的建议 这一部分其实也算是今天的重点，这一部分用来回答很多群里的朋友所问过的问题，那就是LZ你是如何学习Java的，能不能给点建议？ 今天LZ是打算来点干货，因此咱们就不说一些学习方法和技巧了，直接来谈每个阶段要学习的内容甚至是一些书籍。这一部分的内容，同样适用于一些希望转行到Java的同学。 在大家看之前，LZ要先声明两点。 1、由于LZ本人是Java后端开发出身，因此所推荐的学习内容是Java Web和Java后端开发的路线，非Java Web和Java后端开发的同学请适当参考其学习思想即可，切勿照搬。 2、下面对于【第一部分】的推荐内容，目的是让你尽快成为一个可以参加工作的Java开发者，更适用于处于待业状态，准备转行Java的同学。如果你是在校学生，务必要在学好基础（比如计算机系统、算法、编译原理等等）的前提下，再考虑去进行下面的学习。 第一部分：对于尚未做过Java工作的同学，包括一些在校生以及刚准备转行Java的同学 一、Java基础 首先去找一个Java的基础教程学一下，这里可以推荐一个地址，或者你也可以参照这个地址上去找相应的视频。学习Java基础的时候，应该尽量多动手，很多时候，你想当然的事情，等你写出来运行一下，你就会发现不是这么回事儿，不信你就试试。 学完以上内容以后，你应该对Java有一个基本的了解了，你可以用Java语言写出一些简单的程序，并且你用的是最简单的编辑器，比如记事本。这个时候，不要急于进入下一部分，留下几天好好写一些程序，尽可能熟悉这些基础内容。 二、Web开发 等你写上几天程序以后，你往往会比较迷茫，因为你写的东西似乎看起来毫无用处，比如实现一个简单的计算器，读取一个文件等。这个时候你就应该去学着写一些让你觉得有意思的东西了，所以你应该学习更多的知识。 这些内容主要是Web开发相关的内容，包括HTML/CSS/JS（前端页面）、Servlet/JSP（J2EE）以及Mysql（数据库）相关的知识。它们的学习顺序应该是从前到后，因此最先学习的应该是HTML/CSS/JS（前端页面），这部分内容你可以去上面的那个runoob网站上找。 你可以试着自己写一些页面，当然，你可以尽你最大的努力让它变得最漂亮。这部分内容对于后端Java来说，理论上不是特别重要，但至少要达到可以自己写出一些简单页面的水平。 接下来，你需要学习的是Servlet/JSP（J2EE）部分，这部分是Java后端开发必须非常精通的部分，因此这部分是这三部分中最需要花精力的，而且这个时候，你要学会使用开发工具，而不能再使用记事本了，可以选择eclipse。 当你下载安装好eclipse以后，请视频中的教程一步一步去学习，一定要多动手。关于Servlet/Jsp部分视频的选择，业界比较认可马士兵的视频，因此推荐给大家。当然了，LZ本人并没有看过他的视频，所以不好说的太绝对，如果大家自己有更好的选择，可以坚持自己的，不要被LZ干扰。 原本LZ也是打算出教学视频的，但是由于时间问题，还是决定放弃了。但是如果你看视频的过程中遇到了问题，欢迎来LZ的交流群提问，或者去斗鱼观看LZ的直播提出你的问题，直播地址和群号都在LZ的个人博客左侧。 最后一步，你需要学会使用数据库，mysql是个不错的入门选择，而且Java领域里主流的关系型数据库就是mysql。这部分一般在你学习Servlet/Jsp的时候，就会接触到的，其中的JDBC部分就是数据库相关的部分。你不仅要学会使用JDBC操作数据库，还要学会使用数据库客户端工具，比如navicat，sqlyog，二选一即可。 三、开发框架 当你学会以上内容以后，这个时候你还不足以参加工作，你还需要继续深造。公司里为了提高开发的效率，会使用一些Java Web框架，因此你还需要学习一些开发框架。 目前比较主流的是SSM框架，即spring、springmvc、mybatis。你需要学会这三个框架的搭建，并用它们做出一个简单的增删改查的Web项目。你可以不理解那些配置都是什么含义，以及为什么要这么做，这些留着后面你去了解。但你一定要可以快速的利用它们三个搭建出一个Web框架，你可以记录下你第一次搭建的过程，相信我，你一定会用到的。 还要提一句的是，你在搭建SSM的过程中，可能会经常接触到一个叫maven的工具。这个工具也是你以后工作当中几乎是必须要使用的工具，所以你在搭建SSM的过程中，也可以顺便了解一下maven的知识。在你目前这个阶段，你只需要在网络上了解一下maven基本的使用方法即可，一些高端的用法随着你工作经验的增加，会逐渐接触到的。 四、找工作 当你完成开发框架的学习以后，你就该找工作了，在校的找实习，毕业的找全职。与此同时，在找工作的同时，你不应该停下你的学习，准确的说，是你在以后都不能停下学习。 上面这些内容你只是囫囵吞枣的学会了使用，你可以逐步尝试着去了解更多的东西，网络是你最重要的老师。 第二部分：对于参加工作一年以内的同学 恭喜你，这个时候，你已经拥有了一份Java的工作。这个阶段是你成长极快的阶段，而且你可能会经常加班。但是加班不代表你就可以松懈了，永远记得LZ说的那句话，从你入行那一刻起，你就要不停的学习。在这一年里，你至少需要看完《Java编程思想》这本书。这本书的内容是帮助你对于Java有一个更加深入的了解，是Java基础的升级版。 这本书很厚，当初看这本书，LZ花了整整三个月。正常速度的话，应该可以在半年左右看完。LZ这里不要求过高，只要你在一年以内把这本书看完即可。当然了，LZ所说的看完，是充分吸收，而不是读一遍就完事了，因此有些内容你可能会看不止一遍。 总而言之，这个阶段的核心学习思想就是，在工作中实践，并且更加深入的了解Java基础。 第二部分：对于参加工作1年到2年的同学。 这部分时间段的同学，已经对Java有了一个更加深入的了解。但是对于面向对象的体会可能还不够深刻，编程的时候还停留在完成功能的层次，很少会去考虑设计的问题。 于是这个时候，设计模式就来了。LZ当时看的是《大话设计模式》这本书，并且写了完整版的设计模式博客。因此，LZ要求大家，最多在你工作一年的时候，必须开始写博客，而设计模式就是你博客的开端。请记住，LZ所提的基本都是最低要求，因此不要有任何松懈的心理，否则五年后，你不要去羡慕别人高于你的工资，也不要去羡慕别人进入了某公司。 这一年，你必须对于设计模式了如指掌，《大话设计模式》可以作为你的开端。当然了，你也可以去看LZ的个人博客去学习，地址请点击这里。 此外，设计模式并不是你这一年唯一的任务，你还需要看一些关于代码编写优化的书。比如《重构 改善既有代码的设计》，《effective java》。总而言之，这个阶段，你的核心任务就是提高你的代码能力，要能写出一手优雅的代码。 第三部分：对于参加工作2年到3年的同学 有的同学在这个时候觉得自己已经很牛逼了，于是忍不住开始慢慢松懈。请记住，你还嫩的多。这个阶段，有一本书是你必须看的，它叫做《深入理解Java虚拟机》。这本书绝对是Java开发者最重要的书，没有之一。在LZ眼里，这本书的重要性还要高于《Java编程思想》。 这本书的内容是帮助你全面的了解Java虚拟机，在这个阶段，你一定已经知道Java是运行在JVM之上的。所以，对于JVM，你没有任何理由不了解它。 另外，在过去2年的工作当中，你肯定或多或少接触过并发。这个时候，你应该去更加深入的了解并发相关的知识，而这部分内容，LZ比较推荐《Java并发编程实战》这本书。只要你把这本书啃下来了，并发的部分基本已经了解了十之六七。 与此同时，这个阶段你要做的事情还远不止如此。这个时候，你应该对于你所使用的框架应该有了更深入的了解，对于Java的类库也有了更深入的了解。因此，你需要去看一些JDK中的类的源码，也包括你所使用的框架的源码。这些源码能看懂的前提是，你必须对设计模式非常了解。否则的话，你看源码的过程中，永远会有这样那样的疑问，这段代码为什么要这么写？为什么要定义这个接口，它看起来好像很多余？ 由此也可以看出，这些学习的过程是环环相扣的，如果你任何一个阶段拉下来了，那么你就真的跟不上了，或者说是一步慢步步慢。而且LZ很负责的告诉你，LZ在这个阶段的时候，所学习的东西远多于这里所罗列出来的。因此千万不要觉得你已经学的很多了，LZ所说的这些都只是最低要求，不光是LZ，很多人在这个时间段所学习的内容都远超本文的范围。 如果你不能跟上节奏的话，若干年后，如果不是程序猿市场还不错的话，你很可能不仅仅是工资比别人低，公司没别人好，而是根本就找不到工作。 总而言之，这个阶段，你需要做的是深入了解Java底层和Java类库（比如并发那本书就是Java并发java.concurrent的内容），也就是JVM和JDK的相关内容。而且还要更深入的去了解你所使用的框架，方式比较推荐看源码或者看官方文档。 另外，还有一种学习的方式，在2年这个阶段，也应该启用了，那就是造轮子。不要听信那套“不要重复造轮子”的论调，那是公司为了节省时间成本编造出来的。重复造轮子或许对别人没有价值，因为你造的轮子可能早就有了，而且一般情况下你造出来的轮子还没有现存的好。但是对别人没有价值，不代表对你自己没有价值。一个造轮子的过程，是一个从无到有的过程。这个过程可以对你进行系统的锻炼，它不仅考察你的编码能力，还考察你的框架设计能力，你需要让你的轮子拥有足够好的扩展性、健壮性。 而且在造轮子的过程中，你会遇到各种各样的难题，这些难题往往又是你学习的契机。当你把轮子造好的时候，你一定会发现，其实你自己收获了很多。所以，这个阶段，除了上面提到的了解JVM、JDK和框架源码以外，也请你根据别人优秀的源码，去造一个任何你能够想象出来的轮子。 第四部分：参加工作3年到4年的同学 这个阶段的同学，提升已经是很难了，而且这个阶段的学习往往会比较多样化。因为在前3年的过程中，你肯定或多或少接触过一些其它的技术，比如大数据、分布式缓存、分布式消息服务、分布式计算、软负载均衡等等。这些技术，你能精通任何一项，都将是你未来面试时巨大的优势，因此如果你对某一项技术感兴趣的话，这个时候可以深入去研究一下。这项技术不一定是你工作所用到的，但一定是相关的。 而且在研究一门新技术时，切忌朝三暮四。有的同学今天去整整大数据，搞搞Hadoop、hbase一类的东西。过不了一段时间，就觉得没意思，又去研究分布式缓存，比如redis。然后又过不了一段时间，又去研究分布式计算，比如整整Mapreduce或者storm。结果到最后，搞得自己好像什么都会一样，在简历上大言不惭的写上大数据、分布式缓存、分布式计算都了解，其实任何一个都只是浮于表面。到时候面试官随便一问，就把你给识破了。 一定要记住，作为一个程序猿，平日里所接触的技术可能会很多，但是想要让一门技术成为你的优势，那么一定是你对这门技术的了解强过绝大多数人才行。因此在这个阶段，你就不能再简单的去学习前3年的内容了，虽然前面的学习如果还不够深入的话依旧要继续，但这个时候你应该更多的考虑建立你的优势，也可以称为差异性。 差异性相信不难理解，就是让你自己变得与众不同。你前面三年的学习足够你成为一名基本合格的Java开发者，但你离成为一名优秀的Java开发者还有很大的距离。 所谓优秀，即能别人所不能。而你前三年所学习的内容，是很多做过几年的Java开发都能够掌握的。那么为了让自己有差异性，你就需要另辟蹊径，找一个方向深入研究下去，以期在将来，你能够成为这个领域的专家，比如分布式计算领域的专家，大数据领域的专家，并发领域的专家等等。 此外，你除了建立你的差异性之外，还要去弥补你基础上的不足，直到现在，LZ都没有提及基础知识。原因是基础是很枯燥无味的，学的太早不仅容易懵逼，而且懵逼的同时还容易产生心理阴影，以至于以后再不想去研究这些基础。但基础又是你深入研究一些领域时所必须掌握的，比如你去研究分布式计算，你不懂算法你玩个毛毛？比如你去做分布式缓存，你对计算机系统的内存不了解，你如何去做缓存？ 如果你的基础本来就非常强，那么恭喜你，相信你在之前的工作中已经充分体会到了这些基础对你的帮助。但LZ相信大部分人的基础都很薄弱，哪怕是科班毕业的人，很多人也不敢说自己当初的基础学的多么强大，比如算法、计算机系统原理、编译原理这些。 但是每个人时间都是有限的，而且这些基础的书籍每一本读下来，没个一年半载的，还真拿不下来，因此还是要有所抉择的。虽然艺多不压身，但问题是艺多是有代价的，是需要你付出时间和精力的，而LZ个人更赞成在同等代价的情况下获取最大的收获。 首先，LZ比较推崇的基础书籍有三本，分别是《深入理解计算机系统》，《tcp/ip详解 卷一、二、三》，《数据结构与算法》。其中TCP/IP有三本书，但我们这里把这三本看成是一本大书。这三本分别适合三种人，《深入理解计算机系统》比较适合一直从事Java Web开发和APP后端开发工作的人群。《tcp/ip详解 卷一、二、三》比较适合做网络编程的人群，比如你使用netty去开发的话，那么就要对TCP/IP有更深入的了解。而《数据结构与算法》这本书，则比较适合做计算研究工作的人，比如刚才提到的分布式计算。 另外，LZ要强调的是，这里所说的适合，并不是其它两本对你就没有用。比如你做Java Web和APP后端开发，《tcp/ip详解 卷一、二、三》这本书对你的作用也是很大的。这里只是分出个主次关系而已，你要是时间足够的话，能把三本都精读那当然最好不过了。但如果时间有限的话，那么就先挑对你帮助最大的书去读。理论上来讲，这一年你能把这三本其中一本精读下来，就已经非常厉害了。有了基础，有了前面的工作经验，你就可以去开拓属于你的领域了。 在这一年里，一定要规划好自己的领域，建立好自己的优势，制造出差异性。如果你对自己的领域不够清晰的话，随着你工作的时间日益增多，你接触的技术会越来越多，这个时候，你很容易被淹死在技术的海洋里，看似接触的技术越来越多，会用的也越来越多，但你毫无优势。 有的同学可能会问，“LZ，我也不知道我的领域是什么啊？怎么办呢？”对于这种人，LZ只想说，“卧槽，这还问我？要不干脆我替你学习得了，好不好？” 第五部分：参加工作4年到5年的同学 经过前面一年的历练，相信你在自己所钻研的领域已经有了自己一定的见解，这个时候，技术上你应该已经遇到瓶颈了。这个时候不要着急提高自己的技术，已经是时候提高你的影响力了，你可以尝试去一些知名的公司去提高你的背景，你可以发表一些文章去影响更多的人。 当然，你也可以去Github创建一个属于你的开源项目，去打造自己的产品。这次的开源项目不同于之前的造轮子，你这个时候是真的要去尽量尝试造出来真正对别人有价值的轮子。技术学到这个阶段，很容易遇到瓶颈，而且往往达到一定程度后，你再深入下去的收效就真的微乎其微了，除非你是专门搞学术研究的。然而很可惜，大部分程序猿做不到这一步，那是科学家做的事情。 这个时候提高影响力不仅仅是因为技术上容易遇到瓶颈，更多的是影响力可以给你创造更多的机会。程序猿在某种程度上和明星很像，一个好的电视剧和电影就可以成就一批明星，程序猿有的时候也是，一个好的项目就可以成就一群程序猿。 比如国内几个脍炙人口的项目，像淘宝、支付宝、QQ、百度、微信等等。这每一个项目，都成就了一批程序猿。LZ敢说，这里面任何一个项目，如果你是它的核心开发，光是这样一个Title，就已经是你非常大的优势。更何况还不止如此，Title说到底也是个名头，更重要的是，这种项目在做的时候，对你的历练一定也是非常给力的。 而你如果想要参与这样的项目，除了靠运气之外，影响力也是很重要的一个手段。比如你在分布式计算领域有一定的影响力，那么如果有什么好的关于分布式计算的项目，对方就很可能会邀请你。就算人家不邀请你，你自己主动去面试的时候，对方如果知道你在这个领域的影响力，也肯定会起到很大的作用，而这个作用，甚至可能会超过你现在的技术能力。 所以，在这个阶段，你最大的任务是提高自己的影响力，为自己未来的十年工作生涯那一天做准备。如果你能够靠你的影响力和以前积累的技术，参与到一个伟大的项目当中，那么你后面的五年也就有着落了。 当然了，LZ现在满打满算，做程序猿也就4年半不到，因此关于4年到5年这一部分，LZ的见解不一定是对的，就算是对的，也不一定是适合任何人的。所以，希望大家自己有的判断力，去决定到底该如何度过这一年。 结语 本文到此就基本结束了，整篇文章很长，但其实主要就说了两部分内容，一个是社招面试的准备，一个是Java生涯的学习。 关于这两部分，LZ已经给出了自己的见解，但是还是那句话，每个人吸收知识的时候，都要有抽取精华，去除糟粕的能力。LZ所说的，可能有些是对的，有些是错的，有些是适合你的，有些是不太适合你的，你要自己能够判断。 其实你在生活和工作当中也是一样的，你身边的人形形色色，有的人你喜欢，有的人你很讨厌。但其实你喜欢的人也有缺点，你讨厌的人也有优点。你要学会从你讨厌的人身上学会他的优点，千万不要一棒子打死，这只会让你失去很多学习成长的机会。 好了，说了这么多了，就到此为止吧，希望本文可以帮助到作为程序猿或即将成为程序猿的你。 "},"docs/Reprint/program-in-ten-years.html":{"url":"docs/Reprint/program-in-ten-years.html","title":"用十年来学编程","keywords":"","body":"为什么每个人都这么着急？ 走进任何一家书店，你会看到名为《如何在 24 小时内学会 Java》的书，还有各 种各样类似的书： 在几天内或几小时内学会 C，SQL，Ruby，算法等等，一眼望不到 尽头。我在 Amazon 上做了如下的高级检索 ：[title: teach, yourself, hours, since: 2000 ]得到了512 本这样的书。在前十本中有九本是关于编程的书（其它的是关于记账的）。把 “teach yourself” 换成 “learn” 或者用 “hours” 换成 “days”，可以得到了类似的结果。 从上面的搜索结果可以看出来，要么就是人们对计算机技术的学习如饥似渴，要么就是计算机技术实在太简单，不费吹灰之力就能学会。Felleisen 以及其它人在他们的著作《如何设计程序》一书中明确指出了这种“速成”的趋势，并评论到：“垃圾的编程技术当然非常容易，傻子都能在 21 天之内学会，哪怕他天生就是个白痴。” Abtruse Goose 的漫画中也有类似尝试。 让我们分析一下，像一本名为《24 小时内学会 C++》的书意味着什么： 学习： 在 24 小时里，你没有时间写一些重大的程序，并从成功或失败中得益。你没有时间与有经验的程序员合作，并理解在 C++ 的环境下工作是怎么回事。一句话，你不会有时间学到太多东西。因此他们只能谈论一些肤浅的东西，而不是深入的理解。正如亚历山大教皇所说，浅尝辄止是危险的事情。 C++： 在 24小时的时间里，你可能学会 C++ 的语法（如果你 已经学过类似的语言），但你学不到更多的如何使用这些语法的知识。也就是说， 假如你曾是个 BASIC 程序员，你可以学着用 C++ 语法写出 BASIC 风格的程序，但你不可能了解 C++ 真正的好处（和坏处）。那么关键是什么？ Alan Perlis说过：“一种不改变你编程的思维方式的语言，不值得去学。” 一种可 能的情况是：你必须学一点儿 C++（或可能性更大的像 JavaScript 或 Processing 之类），因为你为了完成某种特定的任务，需要与一个现存的工具建立接口。不过那不是学习如何编程，而是在学习如何完成那个任务。 24 小时内： 很不幸，这不够，原因由下一节告诉我们。 在十年里学会编程 研究人员在一系列调查显示，在各个领域内，要想获得专业级别的水平，大约需要 10 年时间的努力。参与此项调查的领域包括：国际象棋，作曲，发报，绘画，钢琴演奏，游泳，网球以及对神经心理学和拓扑学的研究。若要在某一领域内达到专家级的水平，其关键在于“刻意练习”，也就是说，并非是机械地，一遍又一遍地练习，而是要不断地挑战自我，试图超越自身当前的水平，通过不断的尝试挑战，并在尝试的过程中和尝试之后对自身的表现进行分析和总结，吸取经验，纠正之前犯过的各种错误。把这一过程不断重复，才能取得成功。所谓的“捷径”是不存在的，即使对于莫扎特这种天才来说，也没有捷径可走，尽管 4 岁就开始作曲，可是他也花了 13 年的时间，才真正地写出了世界级的作品。再举一个例子，甲壳虫乐队（The Beatles）,他们似乎在 1964 年凭借一系列热门单曲和其在艾德沙利文秀（The Ed Sullivan show）上的演出一炮而红，但是你也许不知道，他们早在 1957 年就在利物浦和汉堡两地进行小规模演出了，而在此之前的非正式演出更是不计其数。甲壳虫乐队的主要成名曲《Sgt. Peppers》，则是 1967 年才发行的。 Malcolm Gladwell推广了这个理念，尽管他的重点在 10000 个小时而不是 10 年。Henri Cartier-Bresson(1908-2004)说过，“你所拍摄的头 10000 张照片都是最糟糕的”。（他没有预料到，有了数码相机后，有些人可以在一周内达到这个数量~）真正的专业或许需要花费一生的时间。Samuel Johnson (塞缪尔 约翰逊 1709-1784)说：“在任何一个领域要想做到极好,势必穷尽一生的精力，否则根本无法企及。” Chaucer (乔叟 1340-1400)也发出过“生命如此短暂，技能如此高深”的感叹。Hippocrates (希波克拉底，约 400BC)因写下了如下的句子而被人称颂：“ars longa, vita brevis”，该句是来自于一个更长的引用：”Ars longa, vita brevis, occasio praeceps, experimentum periculosum, iudicium difficile”, 这段话（拉丁文）翻译成英语就是：“生命很短暂，但是技艺却很高深，机遇转瞬即逝，探索难以捉摸，抉择困难重重”。 显然，没有一个单一的数字可以作为最终的回答：假定所有技能（比如编程，国际象棋，跳棋，音乐）都需要相同的时间来成为专家或者假定任何人都需要一样的时间是没理由的。正如K. Anders Ericsson教授所指出的那样：“在绝大多数领域，哪怕是最有天分的个人，他们达到最高水平所耗费的时间也是极为显著的。10000 小时这个数字只是想让你意识到即便是人们口中的那些最具天赋的个体想达到最高水平也需要年复一年的每周花上 10 到 20 小时。” 你想当程序员么？ 这是我为编程成功开出的方子： 对编程感兴趣，并且因为它有趣而编一些程序。确保编程一直充满足够乐趣，这样你才愿意投入十年/10000 小时宝贵时间。 写程序。 最好的学习方式是从实践中学习。 用更技术性的话说，“在一个给定的领域内，个人的最大能力不 是自动地由扩展了的经验取得的，但即使是高度有经验的人也可以通过有意识的努力来提高自己的能力和 “最有效的学习需要因人而异的适当难度，目标明确的任务，丰富的信息反馈，以及重复的机会和错误修正。”此书 Cognition in Practice: Mind，Mathematics，and Culture in Everyday Life 是阐明此观点的令人感兴趣的参考文献。 与其他程序员交流； 阅读其它程序。这比任何书本或训练课程都重要。 如果愿意，在大学里呆上 4 年（或更长，在研究生院里）。你会接触到一些需要文凭的工作，你会对此领域有更深的理解。如果你不喜欢学校， 你可以（会有所牺牲）依靠自身或在工作中获得相似的经验。在任何情况下，光啃书本是不够的。Eric Raymond，The New Hacker’s Dictionary 一书的作者，说过，“计算机科学不能把任何人变成编程专家，就象光研究刷子和颜料不会使人变成画家一样。” 我雇佣过的最好的程序员之一仅有高中文凭；他做出了许多优秀的软件，有他自己的新闻组， 而且通过股票期权买到了自己的夜总会。 和其他程序员一起做项目。在其中的一些项目中作为最好的程序员； 而在另一些项目中是最差的。当你是最好的，你能测试领导项目的能力，用你 的观点激发别人。当你是最差的，你学习杰出者是怎么做的，了解他们不喜欢做 什么（因为他们吩咐你做事）。 在其他程序员之后接手项目。使自己理解别人写的程序。 当程序的原作者不在的时候，研究什么需要理解并且修改它。思考如何设计你的 程序以便后来者的维护。 学习至少半打的编程语言。包括一种支持类抽象的语言（像 Java 或 C++），一种支持函数化抽象的语言（像 Lisp 或 ML 或 Haskell），一种支持语法抽象的语言（像 Lisp），一种支持声明规格说明的语言（像 Prolog 或 C++ 的模板），以及那些强调并行的语言（像 Clojure 或 Go）。 请记住“计算机科学”中有“计算机”一词。了解你的计算机要花多 长时间执行一条指令，从内存中取一个字（有cache），从磁盘中读取连续的字， 和在磁盘中找到新的位置。 参与一种语言标准化的工作。它可以是 ANSI C++ 委员会， 也可以是决定你周围小范围内的编程风格是应该两个还是四个空格缩进。通过任何一种方式，你了解到其他人在某种语言中的想法，他们的理解深度，甚至一些他们这样想的原因。 具备良好的判断力，能尽快地从语言标准化的纠缠中脱身。 明白了这些，仅从书本中你能得到多少就成了一个问题。在我第一个孩子出生前， 我读了所有的（关于育儿的）How to 书籍，仍然感觉是个手足无措的新手。30 个月以后，我 的第二个孩子快要出生了，我回头温习这些书了吗？ 没有。相反，我依靠我的个人 经验，它比专家写的数千页书更有用和可靠。 Fred Brooks在他的随笔《No Silver Bullet》 中定出了一个寻找优秀软件设计者的三步计划： 尽可能早地，有系统地识别顶级的设计人员。 为设计人员指派一位职业导师，负责他们技术方面的成长，仔细地为他们规划 职业生涯。 为成长中的设计人员提供相互交流和学习的机会。 此计划假设某些人已经具备了杰出设计者的必要才能； 要做的只是如何恰当地诱导他们。 Alan Perlis说得更简明扼要：“每个人都能被教会雕刻：对米开朗其罗而言， 反倒是告诉他哪些事不要做。同样的道理也适用于优秀的程序员。” Perlis 认为，伟大的软件开发人员都有一种内在的特质，这种特质往往比他们所接受的训练更重要。但是这些特质是从哪里来的呢？是与生俱来的？还是通过后天勤奋而来？正如 Auguste Gusteau（动画电影《料理鼠王》里的幻象大厨）所说，“谁都能做饭，但只有那些无所畏惧的人才能成为大厨！”我把“将你生命中的大部分时间花在刻意练习上”更多视作为一种自愿！但或许“无所畏惧”才是概括它的方式。或者，就像是《料理鼠王》里那个与 Gusteau 作对的刻薄的美食评论家 Anton Ego 说的那样：“不是任何人都能成为伟大的艺术家，不过，伟大的艺术家可以来自任何地方。” 所以尽管买本 Java/Ruby/Javascript/PHP 的书吧。你可能会从中学到点儿东西。但作为一个程序员，你不会在 21 天内或 24 小时内改变你的人生，或你实际的水平。你尝试过连续 24 个月不懈努力提高自己么？如果你做到了，好吧，那么你开始上路了。 Why is everyone in such a rush? Walk into any bookstore, and you'll see how to Teach Yourself Java in 24 Hours alongside endless variations offering to teach C, SQL, Ruby,Algorithms, and so on in a few days or hours. The Amazon advanced search for [title: teach, yourself, hours, since: 2000 and found 512 such books. Of the top ten, nine are programming books (the other is about bookkeeping). Similar results come from replacing \"teach yourself\" with \"learn\" or \"hours\" with \"days.\" The conclusion is that either people are in a big rush to learn about programming, or that programming is somehow fabulously easier to learn than anything else. Felleisen et al. give a nod to this trend in their book How to Design Programs, when they say \"Bad programming is easy. Idiots can learn it in 21 days, even if they are dummies.\" The Abtruse Goose comic also had their take. Let's analyze what a title like Teach Yourself C++ in 24 Hours could mean: Teach Yourself: In 24 hours you won't have time to write several significant programs, and learn from your successes and failures with them. You won't have time to work with an experienced programmer and understand what it is like to live in a C++ environment. In short, you won't have time to learn much. So the book can only be talking about a superficial familiarity, not a deep understanding. As Alexander Pope said, a little learning is a dangerous thing. C++: In 24 hours you might be able to learn some of the syntax of C++ (if you already know another language), but you couldn't learn much about how to use the language. In short, if you were, say, a Basic programmer, you could learn to write programs in the style of Basic using C++ syntax, but you couldn't learn what C++ is actually good (and bad) for. So what's the point? Alan Perlis once said: \"A language that doesn't affect the way you think about programming, is not worth knowing\". One possible point is that you have to learn a tiny bit of C++ (or more likely, something like JavaScript or Processing) because you need to interface with an existing tool to accomplish a specific task. But then you're not learning how to program; you're learning to accomplish that task. in 24 Hours: Unfortunately, this is not enough, as the next section shows. Teach Yourself Programming in Ten Years Researchers (Bloom (1985), Bryan & Harter (1899), Hayes (1989), Simmon & Chase (1973)) have shown it takes about ten years to develop expertise in any of a wide variety of areas, including chess playing, music composition, telegraph operation, painting, piano playing, swimming, tennis, and research in neuropsychology and topology. The key is deliberative practice: not just doing it again and again, but challenging yourself with a task that is just beyond your current ability, trying it, analyzing your performance while and after doing it, and correcting any mistakes. Then repeat. And repeat again. There appear to be no real shortcuts: even Mozart, who was a musical prodigy at age 4, took 13 more years before he began to produce world-class music. In another genre, the Beatles seemed to burst onto the scene with a string of #1 hits and an appearance on the Ed Sullivan show in 1964. But they had been playing small clubs in Liverpool and Hamburg since 1957, and while they had mass appeal early on, their first great critical success, Sgt. Peppers, was released in 1967. Malcolm Gladwell has popularized the idea, although he concentrates on 10,000 hours, not 10 years. Henri Cartier-Bresson (1908-2004) had another metric: \"Your first 10,000 photographs are your worst.\" (He didn't anticipate that with digital cameras, some people can reach that mark in a week.) True expertise may take a lifetime: Samuel Johnson (1709-1784) said \"Excellence in any department can be attained only by the labor of a lifetime; it is not to be purchased at a lesser price.\" And Chaucer (1340-1400) complained \"the lyf so short, the craft so long to lerne.\" Hippocrates (c. 400BC) is known for the excerpt \"ars longa, vita brevis\", which is part of the longer quotation \"Arslonga, vita brevis, occasio praeceps, experimentum periculosum, iudicium difficile\", which in English renders as \"Life is short, [the] craft long, opportunity fleeting, experiment treacherous, judgment difficult.\" Of course, no single number can be the final answer: it doesn't seem reasonable to assume that all skills (e.g., programming, chess playing, checkers playing, and music playing) could all require exactly the same amount of time to master, nor that all people will take exactly the same amount of time. As Prof. K. Anders Ericsson puts it, \"In most domains it's remarkable how much time even the most talented individuals need in order to reach the highest levels of performance. The 10,000 hour number just gives you a sense that we're talking years of 10 to 20 hours a week which those who some people would argue are the most innately talented individuals still need to get to the highest level.\" So You Want to be a Programmer Here's my recipe for programming success: Get interested in programming, and do some because it is fun. Make sure that it keeps being enough fun so that you will be willing to put in your ten years/10,000 hours. Program. The best kind of learning is learning by doing. To put it more technically, \"the maximal level of performance for individuals in a given domain is not attained automatically as a function of extended experience, but the level of performance can be increased even by highly experienced individuals as a result of deliberate efforts to improve.\" (p. 366) and \"the most effective learning requires a well-defined task with an appropriate difficulty level for the particular individual, informative feedback, and opportunities for repetition and corrections of errors.\" (p. 20-21) The book Cognition in Practice: Mind, Mathematics, and Culture in Everyday Life is an interesting reference for this viewpoint. Talk with other programmers; read other programs. This is more important than any book or training course. If you want, put in four years at a college (or more at a graduate school). This will give you access to some jobs that require credentials, and it will give you a deeper understanding of the field, but if you don't enjoy school, you can (with some dedication) get similar experience on your own or on the job. In any case, book learning alone won't be enough. \"Computer science education cannot make anybody an expert programmer any more than studying brushes and pigment can make somebody an expert painter\" says Eric Raymond, author of The New Hacker's Dictionary. One of the best programmers I ever hired had only a High School degree; he's produced a lot of great software, has his own news group, and made enough in stock options to buy his own nightclub. Work on projects with other programmers. Be the best programmer on some projects; be the worst on some others. When you're the best, you get to test your abilities to lead a project, and to inspire others with your vision. When you're the worst, you learn what the masters do, and you learn what they don't like to do (because they make you do it for them). Work on projects after other programmers. Understand a program written by someone else. See what it takes to understand and fix it when the original programmers are not around. Think about how to design your programs to make it easier for those who will maintain them after you. Learn at least a half dozen programming languages. Include one language that emphasizes class abstractions (like Java or C++), one that emphasizes functional abstraction (like Lisp or ML or Haskell), one that supports syntactic abstraction (like Lisp), one that supports declarative specifications (like Prolog or C++ templates), and one that emphasizes parallelism (like Clojure or Go). Remember that there is a \"computer\" in \"computer science\". Know how long it takes your computer to execute an instruction, fetch a word from memory (with and without a cache miss), read consecutive words from disk, and seek to a new location on disk. (Answers here.) Get involved in a language standardization effort. It could be the ANSI C++ committee, or it could be deciding if your local coding style will have 2 or 4 space indentation levels. Either way, you learn about what other people like in a language, how deeply they feel so, and perhaps even a little about why they feel so. Have the good sense to get off the language standardization effort as quickly as possible. With all that in mind, its questionable how far you can get just by book learning. Before my first child was born, I read all the How To books, and still felt like a clueless novice. 30 Months later, when my second child was due, did I go back to the books for a refresher? No. Instead, I relied on my personal experience, which turned out to be far more useful and reassuring to me than the thousands of pages written by experts. Fred Brooks, in his essay No Silver Bullet identified a three-part plan for finding great software designers: Systematically identify top designers as early as possible. Assign a career mentor to be responsible for the development of the prospect and carefully keep a career file. Provide opportunities for growing designers to interact and stimulate each other. This assumes that some people already have the qualities necessary for being a great designer; the job is to properly coax them along. Alan Perlis put it more succinctly: \"Everyone can be taught to sculpt: Michelangelo would have had to be taught how not to. So it is with the great programmers\". Perlis is saying that the greats have some internal quality that transcends their training. But where does the quality come from? Is it innate? Or do they develop it through diligence? As Auguste Gusteau (the fictional chef in Ratatouille) puts it, \"anyone can cook, but only the fearless can be great.\" I think of it more as willingness to devote a large portion of one's life to deliberative practice. But maybe fearless is a way to summarize that. Or, as Gusteau's critic, Anton Ego, says: \"Not everyone can become a great artist, but a great artist can come from anywhere.\" So go ahead and buy that Java/Ruby/Javascript/PHP book; you'll probably get some use out of it. But you won't change your life, or your real overall expertise as a programmer in 24 hours or 21 days. How about working hard to continually improve over 24 months? Well, now you're starting to get somewhere... References Bloom, Benjamin (ed.) Developing Talent in Young People, Ballantine, 1985. Brooks, Fred, No Silver Bullets, IEEE Computer, vol. 20, no. 4, 1987, p. 10-19. Bryan, W.L. & Harter, N. \"Studies on the telegraphic language: The acquisition of a hierarchy of habits. Psychology Review, 1899, 8, 345-375 Hayes, John R., Complete Problem Solver Lawrence Erlbaum, 1989. Chase, William G. & Simon, Herbert A. \"Perception in Chess\" Cognitive Psychology, 1973, 4, 55-81. Lave, Jean, Cognition in Practice: Mind, Mathematics, and Culture in Everyday Life, Cambridge University Press, 1988. Answers Approximate timing for various operations on a typical PC: options time execute typical instruction 1/1,000,000,000 sec = 1 nanosec fetch from L1 cache memory 0.5 nanosec branch misprediction 5 nanosec fetch from L2 cache memory 7 nanosec Mutex lock/unlock 25 nanosec fetch from main memory 100 nanosec send 2K bytes over 1Gbps network 20,000 nanosec read 1MB sequentially from memory 250,000 nanosec fetch from new disk location (seek) 8,000,000 nanosec read 1MB sequentially from disk 20,000,000 nanosec send packet US to Europe and back 150 milliseconds = 150,000,000 nanosec Appendix: Language Choice Several people have asked what programming language they should learn first. There is no one answer, but consider these points: Use your friends. When asked \"what operating system should I use, Windows, Unix, or Mac?\", my answer is usually: \"use whatever your friends use.\" The advantage you get from learning from your friends will offset any intrinsic difference between OS, or between programming languages. Also consider your future friends: the community of programmers that you will be a part of if you continue. Does your chosen language have a large growing community or a small dying one? Are there books, web sites, and online forums to get answers from? Do you like the people in those forums? Keep it simple. Programming languages such as C++ and Java are designed for professional development by large teams of experienced programmers who are concerned about the run-time efficiency of their code. As a result, these languages have complicated parts designed for these circumstances. You're concerned with learning to program. You don't need that complication. You want a language that was designed to be easy to learn and remember by a single new programmer. Play. Which way would you rather learn to play the piano: the normal, interactive way, in which you hear each note as soon as you hit a key, or \"batch\" mode, in which you only hear the notes after you finish a whole song? Clearly, interactive mode makes learning easier for the piano, and also for programming. Insist on a language with an interactive mode and use it. Given these criteria, my recommendations for a first programming language would be Python or Scheme. Another choice is Javascript, not because it is perfectly well-designed for beginners, but because there are so many online tutorials for it, such as Khan Academy's tutorial. But your circumstances may vary, and there are other good choices. If your age is a single-digit, you might prefer Alice or Squeak or Blockly (older learners might also enjoy these). The important thing is that you choose and get started. Appendix: Books and Other Resources Several people have asked what books and web pages they should learn from. I repeat that \"book learning alone won't be enough\" but I can recommend the following: Scheme: Structure and Interpretation of Computer Programs (Abelson & Sussman) is probably the best introduction to computer science, and it does teach programming as a way of understanding the computer science. You can see online videos of lectures on this book, as well as the complete text online. The book is challenging and will weed out some people who perhaps could be successful with another approach. Scheme: How to Design Programs (Felleisen et al.) is one of the best books on how to actually design programs in an elegant and functional way. Python: Python Programming: An Intro to CS (Zelle) is a good introduction using Python. Python: Several online tutorials are available at Python.org. Oz: Concepts, Techniques, and Models of Computer Programming (Van Roy & Haridi) is seen by some as the modern-day successor to Abelson & Sussman. It is a tour through the big ideas of programming, covering a wider range than Abelson & Sussman while being perhaps easier to read and follow. It uses a language, Oz, that is not widely known but serves as a basis for learning other languages. Notes T. Capey points out that the Complete Problem Solver page on Amazon now has the \"Teach Yourself Bengali in 21 days\" and \"Teach Yourself Grammar and Style\" books under the \"Customers who shopped for this item also shopped for these items\" section. I guess that a large portion of the people who look at that book are coming from this page. Thanks to Ross Cohen for help with Hippocrates. "},"docs/Reprint/the-battle-between-Intel-and-ARM.html":{"url":"docs/Reprint/the-battle-between-Intel-and-ARM.html","title":"从Intel和ARM争霸战，看看做芯片有多难","keywords":"","body":"原文链接：https://www.jianshu.com/p/1ac347d0420b 这几天中兴事件持续发酵以来，各种议论纷纷扰扰。但我触动最大的，还是碧树西风写的这句话：“ 一碗牛肉面，真的要用牛肉，真的要用面，真的要炖很久，这么简单的道理，偌大一个国家，这么多精英，过去这么多年了，咋就不能懂呢？” 做芯片很难，做核心芯片更难，做需要生态系统的CPU芯片，比大家想象得都要难。本文尝试谈一谈x86生态系统和ARM生态系统的艰难发展历程和残酷的市场竞争，向大家介绍一下做CPU的各种困难，以及眼下能看到的一线希望。 我尽量写得轻松一些，因为其实这个话题很有趣，仔细探究起来，很多看似爆炸性的新闻，其实草蛇灰线伏脉千里，在很早之前就发端了，这其中的故事，真的像演义小说一样好玩。 本文会罗列很多的往事和参考资料，保证有诚意。一些地方没忍住加上了一些三脚猫的分析，欢迎拍砖打脸。 x86生态系统 如今Intel在服务器市场占有率近乎100%，在桌面市场也大于80%，再加上Intel一贯重视宣传，在普通大众的心目中，Intel就是芯片的代称，甚至是高科技的代称。但Intel并非生而如此，它的牛X千真万确是熬出来的，是在列强环伺的竞争环境中杀出来的。 称王 七十年代，在搭上IBM PC这趟快车之前，Intel的8位处理器已经很成功，但也有很多竞争者，Zilog是其中翘楚，它研发的Z80系列产品和Intel的8080兼容，性价比高。一直到90年代，中国很多大学的微机实验课，还在用Zilog的板子。当时还有一款处理器风头不逊于8080系列，即MOS公司的6502。后来MOS把6502的ISA（指令集架构）授权给了众多厂商，流传甚广。70年代苹果创立之初的Apple-I和Apple-II，80年代任天堂的红白机，90年代初的小霸王学习机，90年代末的文曲星，都使用了6502系列的CPU[1]。 IBM PC给了Intel和微软大发展的机会。但它俩必须面对竞争。IBM PC是IBM主导下的一个开放标准，各个零部件都是可以替换的。所以才有了“兼容机”的概念，和延续至今的装机市场。当时IBM要求Intel必须把x86指令集授权给其它厂商，避免CPU供应商一家独大。一份详细的x86兼容处理器生产厂家列表见https://en.wikipedia.org/wiki/List_of_x86_manufacturers。IBM自己也有生成x86兼容CPU的权力。同时，为了限制微软的MS-DOS，IBM自己也做DOS操作系统，名为PC-DOS。 在IBM PC阵营内部，Intel面对其它CPU供应商的竞争，在阵营外部，还要和苹果的Macintosh电脑竞争。当时苹果已经换用Motorola 68000系列CPU，性能强劲，图形界面诱人。当时用Mac的人，逼格要高于用IBM PC的人。 Intel顶着阵营内外的竞争压力，苦心孤诣地发展壮大。这时候潜在的威胁在慢慢酝酿。从1981年的RISC-I开始，精简指令集（RISC）逐步流行起来，诞生了一系列RISC风格的CPU：1985年MIPS公司推出第一款商用的RISC芯片，HP公司在1986年推出PA-RISC，SUN公司在1987年推出SPARC，Motorola在1988年推出MC88000。当时大家普遍认为RISC优于以x86为代表的CISC风格CPU，就连Intel和AMD也害怕在RISC潮流中落伍，AMD在1987年推出了AM29000，Intel在1988年推出了i860/i960。 开始时RISC似乎并没有威胁到桌面市场，MIPS、PA-RISC、SPARC全是用来做服务器和工作站的。被苹果流放的乔布斯用MC88000系列CPU做NeXT桌面电脑，铩羽而归。1986年，英国的Acorn公司推出了一款名为ARM的RISC处理器，次年，它还配了个操作系统叫RISC OS，强攻桌面市场，可惜最终只在英国掀起来了一些波澜[2][3]。 1991年，RISC阵营实实在在地杀入桌面市场。这一年，IBM看到在PC阵营里，Intel和微软这两个小弟坐大，慢慢不受自己的控制，索性拉拢Apple和在RISC市场不得志的Motorola，推出了PowerPC架构，由IBM和Motorola生产芯片，Apple做操作系统和整机，推出全新的Power Macintosh电脑。这三家组成了AIM（Apple-IBM-Motorola）联盟，气势汹汹地向Wintel联盟发起攻击。 结果是Wintel赢了，个中原因众说纷纭。有人说Wintel保持对已有软件的向下兼容，而Apple频繁更换底层的CPU，导致的不兼容气走了用户，然后由此强调软件生态的重要。我则以为，历史的发展有一定的偶然性，如果当时Wintel不是比尔盖茨和格鲁夫在掌舵，而Apple是乔布斯在掌舵，可能结局完全不同。2005年，乔布斯掌舵下的苹果，把Mac里面的CPU由PowerPC换成Intel的芯片，就完成得干脆利落，没怎么受到软件生态的牵绊[4]。 总之，在80年代，大家就已经深深懂得CPU的ISA是软件生态系统的根基，不愿让这个“生态之根”被别人控制。整机和系统的制造商，通过强制CPU厂商给其它厂商授权自己的ISA，来保证有第二家甚至更多的供应商。如果不慎“生态之根”被别人控制了，例如IBM被Wintel篡了权，甚至不惜另起炉灶来竞争。 同样是把自己的指令集授权给其它厂商，Intel把几乎所有的其它供应商都挤死了，只省下AMD苟延残喘；MOS则销声匿迹了，完全靠其它生产商把6502系列延续到了二十一世纪。造成这一差异的原因纵有千万条，我想“打铁还需自身硬”是最根本的。 霸业 在桌面市场上，Windows 95和Windows 98这两款操作系统，让Wintel联盟登上了霸业的顶端。从1995年到2003年，Intel看起来简直是不可战胜的。 与此同时，Intel还把几乎所有的RISC架构的CPU都干趴下了，占领了服务器市场。原因大概有这么几点。 第一，从技术角度讲，RISC是一种设计CPU的理念，而不是具体的某一种ISA。像x86这样的复杂指令集，其实在实现过程中，也能借重RISC的理念。1989年的80486，已经隐隐地可以看到RISC风格的流水线，1995年的Pentium Pro，其核心已经是一个乱序执行的RISC了，只不过多了一个复杂的译码逻辑，把x86指令拆分成RISC风格的微操作。因此从技术角度讲，RISC指令集未必比x86有优势。 第二，RISC成也UNIX，败也UNIX。UNIX和C语言树立了很好的软件开发传统，确保同一套代码可以很方便地在不同CPU之间移植。80年代，一大堆RISC架构的CPU，都可以很快配上自己的UNIX，很快把已有的C语言编写的应用跑在CPU上，然后就可以卖了。SUN公司的SPARC配有Solaris，HP公司的PA-RISC配有HP-UX，IBM公司的PowerPC配有AIX。这些林林总总的UNIX变体，反过来又进一步促使UNIX生态系统中软件开发人员重视代码的可移植性，大家都很小心地围绕POSIX标准来编程，避免过分依赖于某个操作系统独有的功能。这样，一旦Intel芯片携Linux（一种开源的UNIX变体）来和RISC架构的工作站竞争，软件应用就纷纷以很小的移植难度，离开了昂贵的专有UNIX工作站。 第三，当时PC市场比服务器市场大得多，Intel在PC市场的盈利帮助它研发更好的服务器芯片，巨大的出货量降低了芯片的制造成本。研发优势和成本优势，奠定了Intel最终胜利的基础。 这段时间，Intel还几次面临挑战，每次都成功保卫了自己对于生态系统的掌控权。 第一个挑战，来自Internet浏览器。Netscape Navigator诞生后，对微软和Intel都是挑战。虽然当时的动态网页还非常初级，但是已经有人喊出“Web is the computer”的概念。等到Java Applet出现之后，大家更是觉得可以在网页上实现桌面应用的效果，未来只需一个浏览器，就能取代桌面。Netscape的Marc Andreessen在1995年，就着手把Netscape浏览器打造成一个Internet OS[5]。以那个时代的软硬件水平，毫无疑问地，这些尝试失败了。 用一个高层次的软件API，兜住所有的上层应用，然后让底层的硬件，都来支持这个API——这个主意不单单在技术上看起来很炫，从商业上，这是上层应用厂商消解底层平台厂商生态霸权的终极武器。因此，在那之后的二十年里，商业上的尝试一直在持续，包括： 腾讯开发的WebQQ和Q+，在网页里面提供一个类似Windows桌面的应用场景，后来失败了，回退到功能单一的SmartQQ。个中原因，我个人认为还是那个时代的PC性能不够。 腾讯开发的微信小程序，在微信里面通过HTML5和Javascript实现手机App的功能，可以横跨iOS和Android。 谷歌推出ChromeOS和ChromeBook笔记本，里面跑的应用，全都是基于HTML5和Javascript的。 我个人认为，微信小程序几乎一定会成功，它一旦成功，腾讯必然会重燃在PC平台上做Q+的野心。Intel在桌面的霸权，最大的威胁不是AMD，也不是ARM，而很可能是HTML5+Javascript，熟悉“降维打击”的人，对此不会感到意外吧。 第二个挑战，来自虚拟机（Virtual Machine）和JIT（Just-in-time）编译器。先锋是Java的虚拟机JVM，后来微软也推出了DotNet虚拟机，支持C#等语言。虚拟机有一套虚拟的指令集，源代码先被编译到这个虚拟的指令集上，在程序运行时，JIT编译器再把这套虚拟指令集编译为CPU的原生指令集。面向虚拟机开发的程序，例如Java Applet，可以在不同的CPU和操作系统平台上运行。 如果有某个虚拟机，它的指令集可以无缝支持所有的编程语言，还能保证高效率，那么所有CPU的都将被OTT（over-the-top）了，就像短信被微信OTT一样。可惜还没有一个虚拟机可以实现此目标。现在大家熟知的虚拟机，都是和语言绑定的，例如JVM只支持Java、scala、kotlin等；DotNet虚拟机只支持C#、VB.net等；V8只支持Javascript、typescript等；HHVM只支持PHP。同一个VM上跑的语言相互调用很容易，跨VM很难互操作。由于虚拟机实在太多了，它们反而成了新的CPU架构的拦路虎：80年代只需要搞定C语言编译器就能卖Unix工作站，如今ARM服务器要想挑战Intel，必须把所有这些基于VM的编程语言都支持得很好，JIT编译器的效率都要做得比较高才行。 第三个挑战，来自Transmeta公司对x86指令集的Emulation（Emulation这个词很难翻译，索性不翻了）。简单地说，Emulation就是把x86指令集看成一个虚拟机的指令集，然后用类似JIT编译器的技术，在非x86的CPU上跑x86的程序。未经许可用别人的ISA做CPU是违法的，但用Emulation的方式实现ISA则不违法（Intel和Transmeta只打过专利的官司没打过ISA的官司，Intel还输了[6]）。如今最广为人知的Emulator是Qemu，上文提到的x86、MIPS、PowerPC、Sparc、MC68000它都可以支持。一般而言，Emulation会导致性能下降一个甚至若干个数量级，根本不足为虑。 1995年，Transmeta公司成立，经过艰苦的秘密研发，于2000年推出了Crusoe处理器，用Emulation的方式，在一款VLIW（超长指令字）风格的CPU上执行x86的程序，这样就规避了没有x86指令集授权的问题。Transmeta的牛逼在于，虽然是Emulation，但实现了接近Intel处理器的性能，同时功耗低很多。2000年年底Transmeta的IPO大获成功，其风光程度，直到后来谷歌IPO的时候才被超过[7]。 Transmeta最后还是失败了，Intel在渠道上打压它是次要原因，性能不足是主要原因。虽然VLIW在90年代中后期被广为推崇，但事实证明，它的性能比起乱序执行的超标量架构，还是差一截。另外Transmeta的芯片是在台积电制造的，那个时候不比现在，台积电的工艺水平比起Intel还差很多。2000年的时候，PC还远没有性能过剩，性能还是比功耗重要。等到2010年，Intel的Atom处理器慢得一塌糊涂，依然靠着低功耗，点燃了上网本的大火。 Transmeta虽然失败了，Emulation技术仍然在发展。NVidia在2008年购买了Transmeta的低功耗技术的授权。2014年，NVidia推出了Tegra K1芯片[8]，其中的Denver处理器，利用Emulation技术，在底层的7路超标量架构上，实现了ARM64指令集[9][10]。值得注意的是，NVidia拥有ARM64的指令集的授权，它不是用Emulation技术来规避什么，而是用Emulation来提升性能，实现比硬件直接执行还要高的性能。根据评测结果，Denver超过了当时苹果最好的手机CPU[11]。近期推出的Denver2处理器的，性能更是秒杀苹果的A9X和华为的麒麟950[12]。 Emulation技术如果真的发展到了比直接执行还要快，Intel的麻烦才刚刚开始。微软联合高通，推出基于SnapDragon835处理器的笔记本，运行Windows 10操作系统[13]，上面可以安装x86的软件。Intel虽然很不爽，但Emulation并不需要指令集授权，所以他只能警告说，在实现Emulator时，不许侵犯Intel的专利，而这一点，微软和高通肯定早已考虑到了[14][15][16]。 挫折 x86生态系统曾经面对过一次最严重的、近乎灭顶之灾的挑战。这次挑战来自于谁？就来自于它的缔造者Intel。 Intel心不甘情不愿地把自己的x86指令级授权给了AMD等一众供应商，眼睁睁看着他们分享自己的利润，很不爽，于是想在x86之外另起炉灶，建设自己独享的生态系统。正巧在90年代初期，升级64位计算成为一个风潮，1991年有MIPS R4000，1992年有DEC Alpha，1995年有SUN SPARC64。1994年开始，Intel联合HP，准备趁32位升级64位的时机，抛弃原有的x86架构，新推出一个EPIC（Explicitly Parallel Instruction Computing）架构，名为IA64（Intel Architecture 64-bit）[17]。 x86架构兼容老旧应用程序的能力是出了名的。8086把8位的8080升级为16位的时候，80386升级到32位的时候，都完全兼容旧有的程序。直到今天，Intel的处理器依然支持虚拟8086模式，在此模式下，可以运行30多年前的8086程序。升级到64bit的时候，Intel居然要放弃所有之前的8位、16位、32位应用了！可想而知当时在业界会引起怎样的轩然大波。Linux的缔造者Linus Torvalds公开对此表示反对[18]。 IA64进展得并不顺利，EPIC本质上就是一种VLIW，如前所述，VLIW的性能比乱序超标量要差。而且EPIC的编译器非常难以开发。原定1997年就会推出产品，但直到1999年才发布IA64指令集，2001年才推出产品[19]。另外Intel也不敢完全放弃之前的32位x86应用，它给出的解决方案是Emulation，但EPIC不像Transmeta为Emulation做了很多专门优化，跑32位x86应用的性能很差。 这个时候，千年老二AMD站了出来，为x86续命。2000年，它推出了AMD64指令集，延续了x86架构兼容老旧应用程序的优良传统，可以原生执行8位、16位、32位的老程序。2003年，AMD推出Opteron服务器CPU和Athlon64桌面CPU[20][21][22]。 AMD64从技术上和生态上都压了IA64一头，Opteron在服务器市场上为AMD赢得了前所未有的成功。2004年，Intel推出了代号为Nocona的至强服务器CPU，它支持一种称为EM64T的技术，EM64T就是AMD64的马甲。江湖有传言说，Intel曾想提出另外一套不同于AMD64的x86升级64位的方案，但微软为了避免x86生态的分裂，极力阻止了。2012年，Intel推出了最后一代IA64的CPU，关闭了这个不赚钱的产品线。 回顾这段历史，有几点特别令人感慨。首先，即使是看似无比强大不可战胜的Intel，不顾生态系统中其它伙伴的利益，一意孤行也是会撞南墙的。其次，幸好由于历史的原因，x86生态中，AMD和Intel是交叉授权的关系，AMD有权加入3DNow这种多媒体扩展指令，也有权加入64位指令，如果是像如今ARM的架构级授权方式，被授权的企业不能自行加以扩展，那可能还真没有办法阻止Intel了。最后，Intel的执行力还真是超强，掉头极快，EM64T的CPU只比AMD64的CPU晚出了一年（当然不能排除Intel早就有备份方案）。 虽然在IA64上栽了跟头，但Intel靠着自己的技术实力，持续不断地推出性能和功耗表现更好的产品，AMD在64位战役中所取得的优势，慢慢也被消磨掉了。 岁月如梭。进入移动互联网和云计算时代之后，服务器的需求量上升。这时RISC架构的服务器CPU几乎快被消灭干净了，只剩下IBM Power奄奄一息。于是Intel几乎独享了服务器市场扩大所带来的红利。但它却高兴不起来，因为移动市场形成了ARM一家独大的局面，移动终端CPU这个市场，Intel怎么也挤不进去。 正巧Intel在刚刚火过一把的上网本市场里设计了一种低功耗的x86核心，即Atom。Intel以Atom为武器，杀入了手机芯片市场。2012年，Intel的老伙计联想，推出了第一款Intel芯片的手机K800[23]。紧接着还有Motorola的XT890。2013年，中兴、华硕也有产品问世。但三星、小米、华为、OPPO、VIVO等出货量大的厂商，都没有采用Intel的芯片。这些手机大厂，看看x86生态中做整机的联想如何艰难度日，估计心里也是一万个不乐意让Intel到移动领域来继续称王。 到2014年，Intel芯的手机还是没有打开局面，市场唱衰之声一片[24][25]。但Intel并不想放弃[26][27]。手机攻不下，那就攻平板！大厂攻不下，那就攻白牌！嫌我的芯片贵，我就给补贴！又过了两年，平板也没有攻下来。在移动市场赔了上百亿美金的Intel，黯然离场[28][29]。 Intel失利的原因众说纷纭，我觉得根本原因还是竞争力不足。首先，这个时候的台积电已经不是Transmeta家Crusoe芯片诞生时的吴下阿蒙，它生产的手机芯片的功耗和性能并不输给Intel；其次，这次Intel并无生态系统的优势，要靠名为houdini的Emulator来执行ARM指令集的程序[30]，性能打了折扣。试想，Intel芯的手机如果性能和待机时间都是iPhone的两倍，谁能抵挡得住这种诱惑？ 几乎在进攻移动市场的同时，Intel也在推出产品试水物联网市场，只不过没有大举宣传。2013年10月，Intel推出一款叫做伽利略的Arduino开发板[31]，上面的CPU叫做Quark（夸克）。Quark是比Atom（原子）还小的基本粒子，这个名字暗含着轻巧、低功耗的意思。接着，Intel在2014年的CES大会和2016年的IDF大会上，先后推出了升级的爱迪生和焦耳开发板。 Intel的大名和Arduino联系在一起多少有些奇怪。Arduino是一套可以跑在低端MCU上的C语言函数库，是电子创客们的最爱。淘宝上Arduino开发板才几十块钱。焦耳开发板上的处理器是4核心、1.5GHz，跑Arduino太浪费了。和它参数近似的Raspberry PI 3 Model B+开发板，四核64位ARM Cortex A53跑1.2GHz，淘宝价不到200块。焦耳开发板要369美元。谁会当这个冤大头[32]？ 物联网市场极度分散，有无数应用但规模都不大，Intel赚大钱习惯了，在这个微利又需要贴近客户做服务的市场里，百般不适。2017年，Intel悄悄停产了针对物联网市场的开发板[33][34]。 Intel接下来所可能面对的挫折，是ARM侵入服务器和桌面领域。这个话题下文还会有简单分析。 ARM生态系统 近几年ARM风光无限，抢新闻头条的能力不逊于Intel。在很多圈外人看来，这家高科技公司好像是在移动互联网时代新冒出来的，但其实它的历史和几乎和80286一样古老。而且它自诞生以来，就以移动（portable）设备为自己首要的目标市场。它等待一飞冲天的风口，等待了二十年。 发端 前文提到，ARM是Acorn电脑公司创造的。Acorn电脑公司创立于1978年，在80年代初，它用6502系列CPU制造的BBC Micro电脑在英国大获成功。6502的性能慢慢跟不上时代了，Acorn想基于80286开发新的电脑，但是Intel连样片都不给——要是Intel大方些，ARM或许根本就不会诞生。Acorn一气之下开发了ARM（Acorn RISC Machine），这是世界上第一款定位中低端（而非服务器）RISC处理器[35]。1985年，ARM1诞生（但从未被商用），后来Acorn在1986年和1990年分别推出了ARM2和ARM3，1987年推出了RISC OS和桌面电脑Archimedes。它在英国的教育市场获得了一定的成功，但1990年之后，很快被Wintel的生态击败了[36]。 1990年前后，研发掌上电脑成为一股风潮。当时有家叫做Active Book的公司，拿ARM2处理器开发一个叫做Personal Communicator的产品[37]。可惜产品上市前，Active Book被AT&T收购了，AT&T把ARM2换成了自家的Hobbit处理器。幸好东方不亮西方亮，当时的苹果公司看好ARM，把自己研发的Newton平台中的处理器，由AT&T的Hobbit，换成了ARM。这个“彼此互换”的故事听起来让人头大，大家只需要记住，ARM的第一颗商用处理器ARM2，就曾被尝试拿来做手持的电脑。 ARM的东家是Acorn，和苹果在电脑市场上有竞争。苹果公司花了6周时间说服Acorn把ARM独立出来运营。1990年11月27日，合资公司ARM正式成立，苹果、Acorn和VLSI分别出资150万、150万、25万英镑，Acorn把ARM处理器相关的知识产权和12名员工放在了新成立的公司里。此后，ARM的缩写被转而解释为Advanced RISC Machine。为了节省成本，新公司在剑桥附近租了一间谷仓作为办公室，全力为苹果的Newton研发ARM6处理器（4和5这两个编号被跳过去了）。 Newton（牛顿）是苹果花大力气研发的触屏移动技术平台，Newton OS是不同于Mac OS的操作系统（如同后来的iOS）。如果你听过苹果、牛顿和万有引力的故事，应该能体会苹果公司对Newton平台有多么高的期望。Newton平台的第一款产品MessagePad于1993年8月上市了，采用32位ARM610处理器，频率为20MHz，屏幕大小为336×240，重量410克，采用4节7号电池供电，售价699美元（相当于今天的1129美元）。可惜的是，它销量很差，上市头四个月的销量不过5万台[38]。 1998年，中国的恒基伟业公司推出了一款叫做 “商务通”的产品，像极了Newton Messagepad。它采用Dragonball处理器[39]，主频仅16MHz[40]，屏幕大小10汉字x10汉字，重量105克，采用2节5号电池供电，售价人民币1988元。靠着“呼机手机商务通，一个也不能少”的广告，商务通在1999年大卖100万台[41]。虽然2001年后商务通及类似产品很快就被越来越强大的手机挤出了市场，但让人好奇的是，背靠营销能力更加强大的苹果，Newton为何没能一炮而红？ 其中一个重要的原因是，Newton重点宣传的手写识别功能表现很糟糕。而商务通对手写汉字的识别率——根据我个人的体验——还真是不错，考虑到它仅仅16MHz的CPU主频，能做到这么好简直是奇迹。当时商务通部分型号的卖点就是“连笔王”[42]，对潦草的汉字识别得相当好。 软件对于一款产品的重要性，真的是生死攸关啊！ 深耕 扯远了，让我们回到ARM的故事上来。 1990年ARM创立之初，给自己定下的使命是“设计有竞争力的、低功耗、高性能、低成本的处理器，并且使它们成为目标市场中广为接受的标准”，目标市场包括：手持设备（Portable），嵌入式（Embedded Control）和汽车电子（Automotive）。跨越近三十年，这个使命和市场定位始终未变，直到今天。 而且，根据我了解到的知识，ARM是处理器的源代码授权这一商业模式的开创者。如今，芯片设计从Verilog等源代码出发，经过一系列自动化或半自动化的优化步骤，最终形成工厂制造芯片所需要的版图文件；整个过程类似软件从源代码被编译为CPU的机器码。但在80年代，芯片的设计自动化非常原始。七八十年代的处理器授权，都是指令集的授权。Synopsys公司于1986年成立，1987年推出把Verilog编译为门级网表的DesignCompiler[43]，之后基于源代码的芯片自动化设计流程才慢慢地被建立起来。于是源代码授权才成为技术上可行的模式。 ARM从未自己生产过商用的芯片。它只是将自己研发的处理器的源代码的知识产权（IP）授权给芯片厂商，由它们推出最终芯片。受益于这一商业模式，尽管在1993年，Apple的Newton失败了，但ARM并未因为设备卖不出去而亏钱，还幸运地拿到了TI的订单[44]，于是成功盈利了。员工数量也由12人增长到了42人。次年ARM又拿到了三星的订单，员工增长到70多人，搬出了谷仓。除了源代码授权的模式之外，ARM也做指令集授权，1995年，ARM把指令集授权给DEC，DEC很快设计出了性能更好的StrongARM处理器[45]。1997年，StrongARM产品线被卖给Intel，更名为XScale。 1995年，Motorola在香港的研发团队基于MC68000指令集开发出了针对手持设备的DragonBall处理器，在这之后的十年，DragonBall处理器一直都是ARM强大的竞争对手[46]。不但Moto自己的手机用它，Palm、三星、Sony的手机也用它。当然还有前文提到的商务通。ARM相对于Dragonball处理器有什么优势？我认为最大的优势是从客户需求出发的、持续的创新；其次是ARM的开放的商业模式。 RISC指令集一般都采用32位定长指令，代码密度比起x86之类的CISC来要差一些，但手机的存储空间有限，对代码密度的要求高。1994年，ARM为此专门研发了16位的指令集Thumb，以及支持这一指令集的ARM7TDMI[47][48]。 开放授权的商业模式，使得整机厂在选择芯片时，可以找到支持同一指令集的多种芯片产品，不容易被绑架。Nokia作为和Motolora旗鼓相当的手机制造商，肯定不会选择竞争对手的Dragonball，而ARM的技术实力和商业模式，正好符合Nokia的需求[49]。 1997年，Nokia推出了一代经典6110，它采用TI的芯片，处理器核心是ARM7TDMI[50][51][52]。6110是Nokia第一款带红外接口的手机，第一次内置了经典的贪吃蛇游戏，它的界面成为了之后Nokia手机的标准。从此，Nokia和ARM成为了好基友，Nokia的Symbian操作系统，一直都建立在ARM架构的基础上[53]。 1998年，趁着6110大红大紫的东风，ARM在Nasdaq上市了。同一年，SGI公司看到处理器IP授权生意有利可图，把MIPS部门拆分出来，次年MIPS推出了它第一款可授权的处理器设计M4K[54]。此后的十年里，MIPS一直都是ARM有力的竞争对手[55]。 商务通在中国流行的那几年，国际市场上流行性能更高的掌上电脑和智能手机，操作系统包括Palm OS、微软的WinCE、Nokia的Symbian、RIM的Blackberry OS，Motorola的Wisdom OS。在这个领域里，ARM阵营中负责高性能的XScale大放异彩，暴击Dragonball。当Dragonball的频率还停留在33MHz/66MHz时，Xscale已经飙到了200~400MHz。MC68000指令集在手持设备领域败走。Palm OS的1.0~4.0都是基于MC68000指令集的，5.0就换成了ARM。后来Motorola的半导体部门Freescale干脆推出了基于ARM核的iMX系列产品，替代Dragonball产品线。 苹果作为掌上电脑的先行者，却在这次浪潮里无所作为，在Wintel的挤压下，它的桌面业务都已经濒临绝境，无暇顾及其它市场了。1997年，不温不火的Newton从苹果公司独立了出来。当乔布斯回归苹果之后，又火速把Newton收编了回来，并且干净利落地停掉了Newton产品线——乔帮主只想要Newton手里的ARM股份。1998年到2003年，苹果通过出售ARM的股票获利11亿美元。这笔钱，是乔布斯复兴战略的重要燃料，可以说是苹果的救命钱[56][57]。 绽放 经过多年的深耕，ARM在新世纪开始时，已经是手机领域里的王者，依然在为客户的需求做着持续的创新，Java加速技术就是一个典型的例子。 从2000年开始，功能手机的性能提升到了足够高的水平，人们希望在手机上玩比较复杂的游戏，而不仅仅是贪吃蛇。但是手机的处理器和操作系统实在是太分散了，为了方便游戏跑在不同手机上，J2ME平台应运而生[58]。从原理上讲，J2ME和Applet并无不同，都是基于JVM的。Java在并不分散的桌面领域没有获得成功，但在分散的手机领域获得了成功。 J2ME的游戏越做越复杂，但手机的处理能力毕竟有限，桌面和服务器上的JIT编译器在手机上跑得太吃力了。于是ARM在2001年推出了ARM926EJ-S处理器，它支持Jazelle DBX技术，可以直接解码和执行Java的字节码，省掉了JIT编译器的负担[59][60]。这一功能大受欢迎，帮助ARM9系列成为了迄今最受欢迎的ARM处理器，总共有250多个授权厂家，其中100多个授权的是ARM926EJ-S[61]。 在MTK助推山寨功能机火遍神州的那几年，主控芯片所使用的核全部都是ARM9[62]。在iOS和安卓的应用商店诞生之前，功能手机全靠J2ME开发的应用来实现各种炫酷的功能。从某种意义上讲，在低端市场上，Jazelle是助力山寨机火爆的最大幕后功臣。 然而高性能ARM芯片的扛把子XScale，却被Intel于2006年6月卖给了Marvell。这是Intel实施x86-everywhere战略的一个步骤。Intel希望x86的生态也能进入到低功耗的移动领域，而不是用自己先进的工艺制程和设计能力帮ARM建设高端应用的生态。22个月之后，2008年4月，低功耗的Atom芯片诞生了[63]。 高性能ARM芯片的扛把子换成了苹果。2004年，在卖光ARM股票的一年之后，乔布斯决定研发iPhone。2007年1月，在Intel放弃ARM之后仅半年，iPhone诞生了。苹果可不会采用低端市场上死守ARM9那种玩法，iPhone一代就采用了400MHz的ARM11；2009年的iPhone 3GS，升级为600MHz的Cortex A8；2010年的iPhone4，苹果自研的A4芯片升级为1GHz的Cortex A8。接下来苹果自研芯片性能一路狂飙的历程，大家都很熟悉了。 从ARM6到ARM11，这些IP核都是按照兼顾移动设备、汽车电子和嵌入式这三个市场的思路来设计的。从2003年起，ARM把产品线有针对性地划分为A、R、M三个系列，分别对应上述三个市场，而且IP核的名字都统一加上了Cortex的前缀。Cortex A8就是A系列的第一个作品。iPhone 3GS和iPhone4令Cortex A8大火，但让ARM一飞冲天的推手，却是iPhone的竞争对手——安卓（Android）。 有很多文章介绍安卓如何诞生，如何在移动设备领域干掉了除iOS之外的全部对手，毋须赘述。这里只想强调一个被普遍忽略的事实：安卓从诞生之初，就要求应用程序采用Java编写，并且跑在Dalvik虚拟机上；但iPhone上的应用，都是原生的ARM程序。要知道Android手机的处理器性能相对iPhone并无优势。山寨之王MTK于2009年2月推出的首款智能手机芯片MT6516，采用406MHz的ARM9；2008年~2010年间由HTC推出的那几款卖得很好的Android手机，也无非是ARM11和Cortex A8的核，几百兆的频率，这种级别的处理器跑虚拟机还是蛮吃力的。另外虚拟机占用内存大的缺点，也不利于用户体验和降低成本。 谷歌宁可冒着让安卓出师不利的风险，也要推广Dalvik虚拟机。这是为什么？谷歌内部的决策过程我们无从得知。一个合理的猜测是，谷歌不愿看到手机领域里ARM一家独大，它希望给MIPS、x86等其它CPU一个机会。J2ME的成功，让谷歌看到完全建立在虚拟机上的手机应用生态，是完全可能的。Dalvik虚拟机可以跑Java，但并不采用JVM那种基于堆栈的字节码，而是改用一种基于寄存器的方案。这么做当然是为了规避SUN公司（后被Oracle收购）的专利，同时也让无法直接运行JVM字节码的MIPS、x86能够实现轻量级的JIT编译器，无须Jazelle这样的技术。从另外一个角度讲，MIPS在电视、机顶盒、游戏机市场上占优，x86在桌面市场近乎垄断，支持它们，也意味着安卓有可能进军电视和桌面。 安卓对所有CPU而言，都是巨大的机会，谁抓住了这个机会，就可以一举改变竞争格局，实现霸业[64]。 只可惜MIPS公司太不给力，一直也没有搞定靠谱的MIPS版Android。等到2011年1月，Synopsys公司给自家的ARC处理器移植好Dalvik虚拟机和浏览器用的V8虚拟机[65][66]、Android环境已完备的时候，MIPS都还没动静。顺便说一句，Intel曾经的南桥芯片里都有ARC处理器，它是Active Management Technology（AMT）的重要基石[67]。 这个时候，北京的君正公司坐不住了。君正靠做低成本的MP4播放器起家，2011年5月在创业板上市[68]。君正拥有MIPS的架构级授权，对自己研发的XBurst处理器非常自信，准备靠它进攻手机和平板市场。2011年7月，基于君正JZ4760的MIPS智能手机通过Android兼容性测试[69][70]。2011年12月，基于君正JZ4770平台的平板电脑，被谷歌选为Android4.0的首发产品，一时风光无限[71][72][73]。 ARM的强大软件生态此时起到了护城河的作用。基于君正的平板，软件兼容性出了问题。原因在于谷歌没有强求所有的应用都跑在Dalvik虚拟机上，对于部分对性能有苛刻要求的app，例如游戏，谷歌允许用CPU的原生指令集来开发，为此还提供了NDK（Native Development Kit）。对于那些包含了ARM原生指令的游戏，君正的平板要么不支持，要么用emulator支持，总之用户体验都不好。 ARM生态圈里，在2011年，正好有两家芯片厂商异军突起：全志和瑞芯微，它们分别推出了采用Cortex A8处理器的A10芯片和RK2918芯片，成本极低，主打平板和安卓电视盒子。君正的平板梦被它们粉碎了，之后只好转战安卓手表，消沉了很多年。对于MIPS而言，还有一个坏消息是，在它们的强力助推下，电视盒子市场也成了ARM的天下。经营不善的MIPS于2012年卖给了Imagination[74]，Imagination不但没能依靠MIPS在CPU市场中有所作为，反而在GPU市场里也败给了ARM，在2017年被迫整体卖身，MIPS业务卖回给了硅谷公司。 2012~2016年，Intel在安卓市场上挑战ARM，也失败了。于是安卓给CPU带来的红利，全部被ARM吃掉了。随着手机越来越重要，ARM也越来越重要，它所推出的最新的Cortex A系列处理器，被手机芯片争相采用。ARM生态也越来越强大，它的触角，慢慢伸出了手机领域。 渗透 2011年1月，微软在CES宣布要为ARM架构开发Windows 8 RT操作系统[75]。在2012年年底，几乎和Intel芯手机上市的同时，包括微软自家的Surface RT在内的一大批二合一平板设备上市了。Windows 8 RT不支持所有之前为x86平台开发的应用程序，这成为它最大的软肋，相关的产品慢慢销声匿迹了。ARM渗透桌面市场的第一次尝试失败了。 最近微软和高通所推出的ARM芯的Windows 10，吸取了教训，用Eumlation的机制来支持旧有的x86桌面程序。这次尝试能否成功，我们拭目以待。 2009年，ARM推出了Cortex A9处理器，并且用40nm的工艺制造了双核的样片，跑到了2GHz[76]。这是ARM第一次推出乱序超标量的处理器核，而乱序超标量是Intel实现高性能的关键技术，这是非常振奋人心的消息。2010年，Marvell推出了1.6GHz的4核A9的服务器芯片Armada XP[77]。2013年，这款芯片被部署在百度的存储服务器上，这是ARM服务器第一次大规模商用。但Marvell并未继续推出新的服务器芯片[78]。2011年，一家创业公司Calxeda采用Cortex A9，推出了共有480个CPU核的ARM服务器[79]。但它的成就还不如Armada XP，2013年公司就倒闭了[80]。 2012年，AMD收购了一家做高密度服务器的厂商SeaMicro[81]，准备把它所采用的CPU核由Intel的Atom换成ARM架构的CPU。但直到2014年AMD才推出8核Cortex A57的服务器芯片Opteron A1100[82][83]，之后从来也没有认真卖过它。2015年AMD就放弃了SeaMicro这个子品牌，不再做高密度服务器了[84]。 ARM进攻服务器市场的第一次尝试失败了。Marvell和Calxeda都采用的是32位的ARM核，先天不足；AMD则三心二意，毕竟自己还有x86 Server的生意。另外服务器市场对于单核单线程的运算能力也有很高的要求，仅仅有低功耗和高通量（high throughput）是不够的。 在ARMv8这一64位指令集发布之后，Cavium和AppliedMicro这两家老牌网络芯片厂商不约而同地将自己原先芯片中的架构换成了ARMv8[85][86]。因为产品的需要，Cavium和AppliedMicro都有自行设计处理器微架构的能力，前者做MIPS处理器，后者做PowerPC处理器。它们两家做ARMv8处理器时，也都采用了只授权指令集，微架构自研的模式。Cavium共推出过两代基于ARM的产品（2014、2016年），AppliedMicro推出过三代（2013、2015、2017年）。随着产品性能逐渐接近Intel的Xeon E5[87][88]，它们渐渐不再满足于原先的网络领域，开始觊觎服务器市场。 最让人期待的还是高通的Centriq芯片，2015年年底量产24核版本，2016年年底量产升级48核版本[89]，还得到了微软的强力支持[90]。考虑到高通还和贵州成立了合资公司华芯通[91]，Centriq很可能成为在国内大规模商用的第一款ARM服务器芯片。 另外具有国防背景的天津飞腾公司，也有ARM服务器芯片的产品[92]，只是不知道这些产品何时能在通用市场上铺货。 其他确定在研发ARM Server芯片的大厂还包括Broadcom[93]和华为[94]，进度上要略慢一些。 ARM阵营对服务器发起的第二波冲击，阵容要强大得多豪华得多。因此ARM才敢于宣称，在2021年拿下25%的服务器市场份额[95]。 要做好Server CPU，ARM架构还有些功课要一点一点补。多Socket服务器所需要的一致性协议，业界刚刚取得共识准备采用CCIX[96]，但还没有具体的产品出来。做云端虚拟机所必备的虚拟化支持，ARM还有些性能问题[97]。x86处理器提升Throughput的利器超线程技术，ARM阵营尚不能支持。Intel芯片近年来陆续增加的安全特性[98][99][100][101]，也够ARM追赶一阵子的。但目前看来，ARM已经没有致命的短板，蚕食掉Intel的服务器市场份额是板上钉钉的事情，唯一的悬念是究竟多少份额？ 未来ISA将不那么重要 从长远看，半导体厂商对建立于ISA之上的生态系统的掌控力会变弱，而ISA本身，会变得越来越不重要。这是软件技术发展的趋势决定的，如前所述，这些技术在90年代末就已经初有小成了。 第一是Web技术。网页开发领域，有一个大家视若无睹的奇迹：最后居然只有Javascript一种开发语言屹立至今。要知道在服务器端和移动App领域，开发语言多如过江之卿。其中原因我也分析不出。反正js的挑战者（微软的VBScript和谷歌的Dart）都失败了。网页开发领域面临的主要问题是浏览器差异大，API不太兼容。这个问题慢慢在缓解中，一来浏览器战争大局已定，Android和PC上的Chrome，以及iPhone和Mac上的safari是胜者；二来很多网页应用是跑在App里面的，例如微信和支付宝里，这种场景下Javascript的API已经被特定厂商规范过了。 由于开发语言和API的高度统一，H5（HTML5+Javascript）已经成了兼容所有硬件的最通用的软件开发平台。曾经有人鼓吹H5会赶走移动端和PC端的原生程序，后来被打脸了。但是移动端和PC端的原生App中，越来越多的界面是用H5生成的了，微信、支付宝、京东、淘宝、爱奇艺、有道词典……，统统都是这样。 Javascript吞噬一切的进程还在持续。2007年，Stack Overflow的联合创始人Jeff Atwood曾经提出过一条Atwood定律[102][103]：任何能够用JavaScript实现的应用系统，最终都必将用JavaScript实现。十年过去了，此定律基本奏效。把Javascript的一个子集当作汇编语言的asm.js及其后续的WebAssembly，更加使得网页应用有媲美原生应用的潜力，在浏览器里跑Unity3D的游戏都不是问题。 独立的应用程序仍然会是移动和桌面端的主流，因为没有独立程序，不方便做弹窗广告，不方便启动后台进程收集用户信息，不方便引诱用户安装其它独立程序。但Web的能力的确在快速提升，Web Component技术实现了类似GUI库的Widget复用，如今在浏览器里实现Office和IDE的功能都毫无问题（office365.com、docs.google.com、editor.construct.net、腾讯文档[104]）；而WebGL已经能支持Unity3D这种大型游戏框架。照此趋势发展下去，独立应用程序仅仅会作为一个包装而存在，开发者写一套H5，加上不同的包装，就成了PC、Mac、Android、iOS上的独立应用程序，不加包装，就是网站。微软去年开源的ReactXP[105]，就是为了实现这一目标。 这意味着什么？不但底层的CPU被OTT了，操作系统也被OTT了。因为移植一个应用程序到各个平台上，几乎没有什么难度。谁将是生态系统的掌控者？若干个超级App，像微信、QQ、支付宝这样的。它们不但包装自家的应用，其它开发者也可以把自己的应用放在这个包装里面，借重超级App的广泛覆盖度，抵达最终用户。前文提到了，如果微信小程序获得成功，腾讯必然会重拾Q+的野心，把QQ变成桌面上各种H5应用的App Store。 如果真的会这样，微软岂不是会比Intel还着急？拜托，微软已经不是二十年前主要靠卖Windows和Office的光盘赚钱的那家公司了，未来它会专注于云计算[106]。但Intel还和二十年前一样在卖芯片。 第二是编译技术尤其是虚拟机的发展。如今的编程语言太多了，80年代那种搞定C语言编译器就OK的好日子早已过去。任何一个新CPU架构要想在移动、桌面、服务器市场站稳脚跟，都得搞定无数的编译器（包括虚拟机用的JIT编译器），这是个坏消息。但好消息是，搞定这些编译器基本就差不多了，不用劝说开发者重写汇编代码。 老一代程序员对x86处理器架构和汇编都非常熟悉。求伯君当年开发WPS时，手写几十万行汇编[107]；雷军读本科时，是系里20多年来拿过《汇编语言程序设计》满分成绩的两个学生之一[108]；梁肇新开发超级解霸时，把MMX汇编玩得出神入化。感兴趣的读者可以看看梁的《编程高手箴言》[109]，那里面，描绘了一个对现在的程序员而言，完全陌生的世界。在那个世界里，你开发的PC应用程序想要移植到Mac平台上，几乎要完全重写。 如今高层次的编程语言接管了一切，汇编语言从很多学校的本科课程里消失了，入门教材也从C改成了Java，甚至是Javascript或Python。程序员完全不熟悉底层的CPU。即使是真的需要拼性能的场合，编译器也在很大程度上代替了手写汇编。ARM的工程师告诉我说，ARM在开发开源的Compute Library过程中，主要依靠在C源码中加入标注来指导编译器生成SIMD指令，而不是像梁肇新那样手写。 在这种情况下，软件平台厂商就变得非常强势，因为他们知道，应用开发商只需付出重新编译一遍的代价。比如苹果，就要求所有的App都改为64位的[110]。这样，未来苹果在手机CPU里放弃对32位应用的支持时，甚至都不会有人感觉得到。这对于x86生态系统而言，简直是天方夜谭，显然微软对此非常眼馋，并且尝试在Windows 10 S中复制这种掌控力[111]。 至于谷歌，Android把所有应用都跑在虚拟机上的尝试虽然失败了，但如果未来它再针对AR/VR、AI或机器人发布一个什么软件平台的话，就很有可能完全禁止原生程序。 而Oracle，正在努力开发可以支持所有编程语言、能把所有CPU给OTT掉的全新VM：GraalVM[112]。我们拭目以待。 第三是Emulation技术的发展。虽然眼下ARM阵营中靠Emulation进攻Intel的先锋是高通，但最可怕的选手其实是NVidia。NVidia拥有最厉害的Emulation技术，而且江湖传言Denver处理器的初衷就是针对x86的[113]。当初NVidia的Tegra处理器曾被拿来做Windows 8 RT的二合一平板[114]。如今Denver处理器跑Windows 10绝不会让人意外，那么它会怎么跑呢？肯定是直接在底层硬件上做x86的Emulation，而不是在Emulate出来的ARM指令集上再做一层Eumulation。 Denver处理器前些年没有跳出来抢Intel的饭碗，很大程度上是因为NVidia还在做Intel平台的主板芯片组，另外NVidia还没有那么强大。如今NVidia也不做芯片组生意了，还借AI的东风，股价扶摇直上。说不定哪天，NVidia就会放出Denver处理器的x86 Emulator，做到单线程性能不输Xeon，强攻服务器市场。想想看，在单芯片上集成GPU和x86版的Denver，云计算厂商能不动心？ 如果未来Emulation技术进一步发展并且被越来越多的厂商掌握，很可能会出现这种情况：CPU本身是某种外界不了解的指令集，官方发布时，只能Emulate某种开放的指令集，例如RISCV；但是用户可以给它安装不同的Emulator，让它变成x86-64处理器，或者ARM64处理器。在软件定义一切的时代，这并不是多么疯狂的想象。 总之，CPU依然不可或缺，但CPU用谁家的，是什么指令集，会越来越不重要。软件的发展，会在用户和底层的CPU之间加入足够大的缓冲带，CPU的差异，越来越难以被用户察觉到。 展望：让CPU不再难 此文在最后修改之时，看到了梁宁的文章《一段关于国产芯片和操作系统的往事》，里面写到：“就像10多年前一样，只要搞定知识产权问题，选择技术路线，找会干的人，投入干，CPU／芯片就能够做出来。搞不定的依然是操作系统。差距大的依然是生态。当年，绕得过Intel，跨不过微软。如今，绕得过Arm，做不出安卓。” 我也曾参与过国产CPU的研发（但不是梁宁提到的方舟），生态之难体会颇深，真的，只是烧钱做芯片，无论烧多少都无法挑战Intel和ARM，何况过去二十年真的没烧多少。 但我并没有梁宁那么悲观，毕竟技术的潮流无法抗拒，借用马化腾的一句名言“可能你什么错都没有，最后就是错在自己太老了”。 Intel和ARM如此强大而且极少犯错，我们如此弱小就算它们犯错也无法利用——但我们可以欺负它们的“老”。 在此借新智元的宝地，向小马哥呼吁一声： 请借助腾讯的强大生态，把CPU和OS这两个老大难问题给OTT掉吧！ 做法非常简单，把Q+桌面再重新搞起来，做一款完全使用Javascript&Webassembly编程的操作系统，里面用腾讯文档来替代Office，各种微信小程序都支持起来，适当支持游戏（但要加入家长监控系统）。补贴芯片厂，让它们使用ARM或RISC-V外加国产Imagination gpu做SoC，生产类似Surface这样的二合一平板。底层CPU使用的ISA完全不可见，上层编程完全用H5。这样，就帮祖国把CPU和OS这两个陈年大洞都补上了。 芯片要下苦功，别凡事都指望模式创新。这不假。但偏偏CPU真的面临一个十倍速变革的机会，真的有靠模式创新而胜出的机会，为什么不试试呢？如果腾讯不去尝试一下，谁还有资格呢？促进祖国的微电子发展功德无量，相信这次不会有人说腾讯垄断之类的闲话。 "},"docs/Reprint/ajxa-fetch.html":{"url":"docs/Reprint/ajxa-fetch.html","title":"Ajxa已死，fetch永生","keywords":"","body":"原谅我做一次标题党，Ajax 不会死，传统 Ajax 指的是 XMLHttpRequest（XHR），未来现在已被 Fetch 替代。 最近把阿里一个千万级 PV 的数据产品全部由 jQuery 的 $.ajax 迁移到 Fetch，上线一个多月以来运行非常稳定。结果证明，对于 IE8+ 以上浏览器，在生产环境使用 Fetch 是可行的。 由于 Fetch API 是基于 Promise 设计，有必要先学习一下 Promise，推荐阅读 MDN Promise 教程。旧浏览器不支持 Promise，需要使用 polyfill es6-promise 。 本文不是 Fetch API 科普贴，其实是讲异步处理和 Promise 的。Fetch API 很简单，看文档很快就学会了。推荐 MDN Fetch 教程 和 万能的WHATWG Fetch 规范 Why Fetch XMLHttpRequest 是一个设计粗糙的 API，不符合关注分离（Separation of Concerns）的原则，配置和调用方式非常混乱，而且基于事件的异步模型写起来也没有现代的 Promise，generator/yield，async/await 友好。 Fetch 的出现就是为了解决 XHR 的问题，拿例子说明： 使用 XHR 发送一个 json 请求一般是这样： var xhr = new XMLHttpRequest(); xhr.open('GET', url); xhr.responseType = 'json'; xhr.onload = function() { console.log(xhr.response); }; xhr.onerror = function() { console.log(\"Oops, error\"); }; xhr.send(); 使用 Fetch 后，顿时看起来好一点 fetch(url).then(function(response) { return response.json(); }).then(function(data) { console.log(data); }).catch(function(e) { console.log(\"Oops, error\"); }); 使用 ES6 的 箭头函数 后： fetch(url).then(response => response.json()) .then(data => console.log(data)) .catch(e => console.log(\"Oops, error\", e)) 现在看起来好很多了，但这种 Promise 的写法还是有 Callback 的影子，而且 promise 使用 catch 方法来进行错误处理的方式有点奇怪。不用急，下面使用 async/await 来做最终优化： 注：async/await 是非常新的 API，属于 ES7，目前尚在 Stage 1(提议) 阶段，这是它的完整规范。使用 Babel 开启 runtime 模式后可以把 async/await 无痛编译成 ES5 代码。也可以直接使用 regenerator 来编译到 ES5。 try { let response = await fetch(url); let data = response.json(); console.log(data); } catch(e) { console.log(\"Oops, error\", e); } // 注：这段代码如果想运行，外面需要包一个 async function duang~~ 的一声，使用 await 后，写异步代码就像写同步代码一样爽。await 后面可以跟 Promise 对象，表示等待 Promise resolve() 才会继续向下执行，如果 Promise 被 reject() 或抛出异常则会被外面的 try...catch 捕获。 Promise，generator/yield，await/async 都是现在和未来 JS 解决异步的标准做法，可以完美搭配使用。这也是使用标准 Promise 一大好处。最近也把项目中使用第三方 Promise 库的代码全部转成标准 Promise，为以后全面使用 async/await 做准备。 另外，Fetch 也很适合做现在流行的同构应用，有人基于 Fetch 的语法，在 Node 端基于 http 库实现了 node-fetch，又有人封装了用于同构应用的 isomorphic-fetch。 注：同构(isomorphic/universal)就是使前后端运行同一套代码的意思，后端一般是指 NodeJS 环境。 总结一下，Fetch 优点主要有： 语法简洁，更加语义化 基于标准 Promise 实现，支持 async/await 同构方便，使用 isomorphic-fetch Fetch 启用方法 下面是重点↓↓↓ 先看一下 Fetch 原生支持率： 原生支持率并不高，幸运的是，引入下面这些 polyfill 后可以完美支持 IE8+ ： 由于 IE8 是 ES3，需要引入 ES5 的 polyfill: es5-shim, es5-sham 引入 Promise 的 polyfill: es6-promise 引入 fetch 探测库：fetch-detector 引入 fetch 的 polyfill: fetch-ie8 可选：如果你还使用了 jsonp，引入 fetch-jsonp 可选：开启 Babel 的 runtime 模式，现在就使用 async/await Fetch polyfill 的基本原理是探测是否存在 window.fetch 方法，如果没有则用 XHR 实现。这也是 github/fetch 的做法，但是有些浏览器（Chrome 45）原生支持 Fetch，但响应中有中文时会乱码，老外又不太关心这种问题，所以我自己才封装了 fetch-detector 和 fetch-ie8 只在浏览器稳定支持 Fetch 情况下才使用原生 Fetch。这些库现在每天有几千万个请求都在使用，绝对靠谱！ 终于，引用了这一堆 polyfill 后，可以愉快地使用 Fetch 了。但要小心，下面有坑： Fetch 常见坑 Fetch 请求默认是不带 cookie 的，需要设置 fetch(url, {credentials: 'include'}) 服务器返回 400，500 错误码时并不会 reject，只有网络错误这些导致请求不能完成时，fetch 才会被 reject。 竟然没有提到 IE，这实在太不科学了，现在来详细说下 IE IE 使用策略 所有版本的 IE 均不支持原生 Fetch，fetch-ie8 会自动使用 XHR 做 polyfill。但在跨域时有个问题需要处理。 IE8, 9 的 XHR 不支持 CORS 跨域，虽然提供 XDomainRequest，但这个东西就是玩具，不支持传 Cookie！如果接口需要权限验证，还是乖乖地使用 jsonp 吧，推荐使用 fetch-jsonp。如果有问题直接提 issue，我会第一时间解决。 标准 Promise 的不足 由于 Fetch 是典型的异步场景，所以大部分遇到的问题不是 Fetch 的，其实是 Promise 的。ES6 的 Promise 是基于 Promises/A+ 标准，为了保持简单简洁，只提供极简的几个 API。如果你用过一些牛 X 的异步库，如 jQuery(不要笑) 、Q.js 或者 RSVP.js，可能会感觉 Promise 功能太少了。 没有 Deferred Deferred 可以在创建 Promise 时可以减少一层嵌套，还有就是跨方法使用时很方便。 ECMAScript 11 年就有过 Deferred 提案，但后来没被接受。其实用 Promise 不到十行代码就能实现 Deferred：es6-deferred。现在有了 async/await，generator/yield 后，deferred 就没有使用价值了。 没有获取状态方法：isRejected，isResolved 标准 Promise 没有提供获取当前状态 rejected 或者 resolved 的方法。只允许外部传入成功或失败后的回调。我认为这其实是优点，这是一种声明式的接口，更简单。 缺少其它一些方法：always，progress，finally always 可以通过在 then 和 catch 里重复调用方法实现。finally 也类似。progress 这种进度通知的功能还没有用过，暂不知道如何替代。 最后 Fetch 替换 XHR 只是时间问题，现在看到国外很多新的库都默认使用了 Fetch。 最后再做一个大胆预测：由于 async/await 这类新异步语法的出现，第三方的 Promise 类库会逐渐被标准 Promise 替代，使用 polyfill 是现在比较明智的做法。 "}}